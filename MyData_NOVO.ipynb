{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98161604",
   "metadata": {},
   "source": [
    "# import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2f5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "\n",
    "rcParams['figure.figsize'] = [16., 5.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efa546",
   "metadata": {},
   "source": [
    "### Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0854ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definições de filtros\n",
    "\n",
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7799f",
   "metadata": {},
   "source": [
    "### Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotData(dirs):\n",
    "#     data = np.load(\"datasets/topicos_cc/\"+dirs)\n",
    "#     data = np.transpose(data, (0, 2, 1))\n",
    "#     print(data.shape)\n",
    "#     data_filtered = butter_notch(data, 60)\n",
    "#     data_filtered = butter_highpass(data_filtered, 5)\n",
    "#     data_filtered = butter_lowpass(data_filtered, 50)\n",
    "#     for i in range(data_filtered.shape[1]):\n",
    "#         plt.plot(data_filtered[0,i,:])\n",
    "#     plt.suptitle(dirs)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8954b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSujeito(dirs):\n",
    "    data = np.load(\"datasets/topicos_cc/\"+dirs)\n",
    "    data = np.transpose(data, (0, 2, 1))\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    \n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d851379",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [ i.split(\"/\")[-1] for i in glob('datasets/topicos_cc/p1*')]\n",
    "data = []\n",
    "for d in dirs:\n",
    "    data.append(loadSujeito(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69570f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3c6022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 4, 1600)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58570d7f",
   "metadata": {},
   "source": [
    "### Visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in dirs:\n",
    "#     plotData(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c5b4d",
   "metadata": {},
   "source": [
    "# Concatenando Trials x Movimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df025f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrada = data_array[0]\n",
    "X = []\n",
    "X.append(data_array[1])\n",
    "X.append(data_array[2])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0e6ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 4, 1600), (8, 4, 1600))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#X = data.reshape(24, 4, 1600)\n",
    "X = np.concatenate((np.array(X)), axis=0)\n",
    "\n",
    "X.shape, X_entrada.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba37c5",
   "metadata": {},
   "source": [
    "## Segmentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89833020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "\n",
    "def segmentacao(X):\n",
    "    data = X\n",
    "    step = 11.8\n",
    "    segment = 128\n",
    "    # data = X.reshape(24, 4, 1600)\n",
    "    # print('', data.shape)\n",
    "\n",
    "    n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "    ids = np.arange(n_win) * int(step)\n",
    "\n",
    "    # Janelas do dado no dominio do tempo\n",
    "    chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "    # Janelas do dado no domínio da frequência\n",
    "    _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "    chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "    print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "    print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "    print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "    return chunks_time, chunks_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9744dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (16, 4, 125, 128) - (classes+ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (16, 4, 125, 65) - (classes+ensaios, canais, janelas, linhas)\n",
      "\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (8, 4, 125, 128) - (classes+ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (8, 4, 125, 65) - (classes+ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "chunks_time, chunks_freq = segmentacao(X)\n",
    "print()\n",
    "chunks_time_entrada, chunks_freq_entrada = segmentacao(X_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e27a756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 4, 125, 128), (16, 4, 125, 65))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_time.shape, chunks_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e642d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "701ff37e",
   "metadata": {},
   "source": [
    "## Achar as Janelas\n",
    "O mesmo que a função acima, mas generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import stft\n",
    "\n",
    "# def janela(overl=64):\n",
    "    \n",
    "#     for i in np.arange(1, 128, 0.1):\n",
    "#         step = i\n",
    "#         segment = 128\n",
    "#         data = X.reshape(24, 4, 1600)\n",
    "        \n",
    "#         _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=overl)\n",
    "#         chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "#         window = chunks_freq.shape[2] \n",
    "\n",
    "#         n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "#         ids = np.arange(n_win) * int(step)\n",
    "\n",
    "#         # Janelas do dado no dominio do tempo\n",
    "#         chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "#         time_window = chunks_time.shape[2]\n",
    "            \n",
    "#         if( time_window == window ):\n",
    "#             return step\n",
    "        \n",
    "    \n",
    "# step = janela(overl=64)\n",
    "# print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334267a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_steps = []\n",
    "# for i in [0.5, 0.7, 0.8, 0.9 ]:\n",
    "#     n_step = int(128*i)\n",
    "#     print(n_step)\n",
    "#     step = janela(overl=n_step)\n",
    "#     all_steps.append(step)\n",
    "    \n",
    "# all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba15e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import stft\n",
    "\n",
    "# def time_freq(step):\n",
    "    \n",
    "#     segment = 128\n",
    "#     data = X.reshape(24, 4, 1600)\n",
    "#     print('', data.shape)\n",
    "\n",
    "#     n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "#     ids = np.arange(n_win) * int(step)\n",
    "\n",
    "#     # Janelas do dado no dominio do tempo\n",
    "#     chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "#     # Janelas do dado no domínio da frequência\n",
    "#     _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=64)\n",
    "#     chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "#     print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "#     print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "#     print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "#     return chunks_time, chunks_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf680e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks_time , chunks_freq = time_freq(11.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabb365",
   "metadata": {},
   "source": [
    "## Extração e seleção de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c7c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZC(data, th):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    \n",
    "    for i in range(tamanho-1):\n",
    "        resultado = (data[i] * data[i+1] )\n",
    "        resultado2 = np.abs(data[i] - data[i+1])\n",
    "        if(resultado < 0 ) and (resultado2 > th):\n",
    "            somatoria += 1\n",
    "        \n",
    "    return somatoria\n",
    "\n",
    "def fj(i, sampleRate, tamanho):\n",
    "    return i * sampleRate / (2 * tamanho)\n",
    "\n",
    "def getFMN(data):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    sumPSD = np.sum(PSD(data))\n",
    "    for i in range(tamanho):\n",
    "        somatoria += (fj(i, 41, tamanho) * PSD(data[i]) ) / sumPSD\n",
    "        \n",
    "    return somatoria\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae201a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "def wamp(x, th):\n",
    "    res = np.abs(np.diff(x))\n",
    "    return np.sum(res >= th, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    res = np.abs(np.diff(x))\n",
    "    return np.sum(res, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "def zc(data,threshold):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                fy.append( getZC(data[xx][yy][zz], threshold ) )\n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def fmn(data):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                \n",
    "                fy.append( getFMN(data[xx][yy][zz]) )\n",
    "                \n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def A(w):\n",
    "    return np.abs(w)\n",
    "\n",
    "def getMMNF(data):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    \n",
    "    sumA = np.sum(A(data))\n",
    "    \n",
    "    for i in range(tamanho):\n",
    "        somatoria += (fj(i, 200, tamanho) * A(data[i]) ) / sumA \n",
    "        \n",
    "    return somatoria\n",
    "\n",
    "def mmnf(data):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                \n",
    "                fy.append( getMMNF(data[xx][yy][zz]) )\n",
    "                \n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def logD(data):\n",
    "    from math import e\n",
    "    N = np.prod(data.shape)\n",
    "    \n",
    "    return e ** ( np.sum(np.log10( np.abs(data) ), axis=-1) ) / N\n",
    "\n",
    "def iemg(data):\n",
    "    # tempo\n",
    "    return np.sum(A(data), axis=-1)\n",
    "\n",
    "def dasdv(data):\n",
    "    #tempo\n",
    "    return np.sqrt( np.sum(np.diff(data) ** 2, axis=-1) / (np.prod(data.shape[:-1]) - 1) )\n",
    "\n",
    "def tmx(x, n):\n",
    "    N = np.prod(x.shape[:-1])\n",
    "    return np.abs(np.sum(x ** n, axis=-1) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d388f98",
   "metadata": {},
   "source": [
    "## Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cced9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_filtros(chunks_time, chunks_freq):\n",
    "    th = np.median(chunks_time)\n",
    "    #VAR, RMS, WL, TM5 e DASDV\n",
    "    #WL, IEMG, LOGD\n",
    "    final_data = list()\n",
    "    final_data.append(var(chunks_time))\n",
    "    final_data.append(rms(chunks_time))\n",
    "    final_data.append(wamp(chunks_time, th))\n",
    "    final_data.append(logD(chunks_time))\n",
    "    final_data.append(wl(chunks_time))\n",
    "    final_data.append(zc(chunks_time,0))\n",
    "\n",
    "    final_data.append(iemg(chunks_time))\n",
    "    final_data.append(dasdv(chunks_time))\n",
    "    final_data.append(tmx(chunks_time, 3))\n",
    "    final_data.append(tmx(chunks_time, 4))\n",
    "    final_data.append(tmx(chunks_time, 5))\n",
    "\n",
    "    final_data.append(fmd(chunks_freq))\n",
    "    final_data.append(mmdf(chunks_freq))\n",
    "    final_data.append(fmn(chunks_freq))\n",
    "    final_data.append(mmnf(chunks_freq))\n",
    "\n",
    "    f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "    final_data.append(Pxx_den)\n",
    "\n",
    "    return np.array(final_data)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f852615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117883/3601286709.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  final = np.array(final_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "th = np.median(chunks_time)\n",
    "\n",
    "\n",
    "#VAR, RMS, WL, TM5 e DASDV\n",
    "#WL, IEMG, LOGD\n",
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(wamp(chunks_time, th))\n",
    "final_data.append(logD(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time,0))\n",
    "\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "final_data.append(tmx(chunks_time, 3))\n",
    "final_data.append(tmx(chunks_time, 4))\n",
    "final_data.append(tmx(chunks_time, 5))\n",
    "\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95a0b522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117883/211142670.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_data)\n"
     ]
    }
   ],
   "source": [
    "final = final_filtros(chunks_time, chunks_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61ec3d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_entrada = final_filtros(chunks_time_entrada, chunks_freq_entrada)\n",
    "\n",
    "final.shape, final_entrada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_entrada[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4019a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = final.transpose(0, 1, 3, 2)\n",
    "# sh = data.shape\n",
    "\n",
    "# X = data.reshape(sh[0], int(sh[1]/3), 3 * sh[2], sh[3])\n",
    "\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7399aa",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# features = list()\n",
    "# for f in X:\n",
    "#     classes = list()\n",
    "#     for c in f:\n",
    "#         C_pca = pca.fit_transform(c)\n",
    "#         classes.append(C_pca)\n",
    "#     features.append(classes)\n",
    "\n",
    "# X_pca = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacdef8",
   "metadata": {},
   "source": [
    "## Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_features(features, features_names, classes_names, ch_1, ch_2):\n",
    "    \n",
    "#     movs = np.arange(len(classes_names))\n",
    "#     markers = [\"o\", \"v\", \"^\", \"P\", \"*\", \"x\", \"X\", \"2\", \"3\", \"1\", 'm', 'L', 'z', 'U', '6']\n",
    "#     for f, feature in enumerate(features):\n",
    "        \n",
    "#         for mov, marker in zip(movs, markers):\n",
    "#             # argumentos: classes, amostras, canal\n",
    "#             plt.scatter(feature[mov, :, ch_1],\n",
    "#                         feature[mov, :, ch_2], marker=marker)\n",
    "\n",
    "#         plt.legend((classes_names), scatterpoints=1, loc='best',\n",
    "#                    ncol=3, fontsize=8)\n",
    "        \n",
    "#         plt.title(features_names[f])\n",
    "#         plt.xlabel('CH{}'.format(ch_1))\n",
    "#         plt.ylabel('CH{}'.format(ch_2))\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'iemg','dasdv','tm3','tm4','tm5', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# classes = [str(item) for item in list(range(8))]\n",
    "# plot_features(X_pca, features_name, classes, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f099f",
   "metadata": {},
   "source": [
    "## Transpose para Selecionar Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape\n",
    "# 24*26 ,9, 4\n",
    "# 24*26 , 10, 4\n",
    "# 24*26 , 15, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = final.transpose(1, 3, 2, 0)\n",
    "X = data.reshape(data.shape[0]*data.shape[1], data.shape[2]*data.shape[3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.array(list(range(1, 9)) * int(X.shape[0] / 8)) # Antigo\n",
    "\n",
    "y = [ [(i)] * int(X.shape[0] / 8 ) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acc6aa",
   "metadata": {},
   "source": [
    "## Seleção de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb84a3",
   "metadata": {},
   "source": [
    "## Variance Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # teste\n",
    "\n",
    "# data_t = final.transpose(1, 3, 2, 0)\n",
    "# ## X_t = data.reshape(24*26, 9, 4)\n",
    "# ## X_t = data.reshape(24*26, 10, 4)\n",
    "# ## X_t = data.reshape(24*26, 15, 4)\n",
    "# X_t = data.reshape(24*26, 5, 4)\n",
    "\n",
    "# data_t = X_t.transpose(2, 0, 1)\n",
    "# data_t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da98e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# canais = list()\n",
    "\n",
    "# for c in data_t:\n",
    "#     sel = VarianceThreshold(threshold=(.1))\n",
    "#     vt = sel.fit_transform(c)\n",
    "#     canais.append(vt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65210499",
   "metadata": {},
   "source": [
    "### RFE (Por causa do Kernel Linear não iremos utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.svm import SVC\n",
    "# estimator = SVC(kernel=\"linear\")\n",
    "# selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "# selector = selector.fit(X, y)\n",
    "# s = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f20d2",
   "metadata": {},
   "source": [
    "### GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import GenericUnivariateSelect, chi2\n",
    "# transformer = GenericUnivariateSelect(chi2, mode='k_best', param=10)\n",
    "# X_new = transformer.fit_transform(X, y)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# X_new = SelectKBest(k=10).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35750a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757f58e",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6284f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# X_new_norm = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2119f3",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d1447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "def do_svm(X,y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "\n",
    "    clf = SVC(gamma='scale')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "do_svm(X,y), do_svm(X_norm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781c4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e82d8c",
   "metadata": {},
   "source": [
    "# Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         acc = do_svm(X_norm.take(res, axis=1), y)\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_comb = res\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}\")\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# for i in best_comb:\n",
    "#     print(f\" {i} --- {features_name[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d39a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         acc = do_svm(X.take(res, axis=1), y)\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_comb = res\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}\")\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# for i in best_comb:\n",
    "#     print(f\" {i} --- {features_name[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb90af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# best_k = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         for ks in range(1,41):\n",
    "#             X_new = SelectKBest(k=ks).fit_transform(X, y)\n",
    "#             acc = do_svm(X_new_norm.take(res, axis=1), y)\n",
    "\n",
    "#             if acc > best_acc:\n",
    "#                 best_acc = acc\n",
    "#                 best_comb = res\n",
    "#                 best_k = ks\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}, Melhor K: {best_k}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e3cfe",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e855a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb16452",
   "metadata": {},
   "source": [
    "## Divisão dos dados em treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividindo em conjuntos de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y, test_size=0.3)\n",
    "\n",
    "# treino: 80% dos 80% de treino. Validacao: 20% dos 80% de treino.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3948c1",
   "metadata": {},
   "source": [
    "## Aplicação do algoritmo de MLP e geração dos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5290d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(lr=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=550, batch_size=15,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# score = model.predict_classes(X_test)\n",
    "# y_true = [np.where(x == 1)[0][0] for x in y_test]\n",
    "\n",
    "predict_x=model.predict(X_test) \n",
    "score=np.argmax(predict_x,axis=1)\n",
    "y_true = y_test\n",
    "\n",
    "print('Acurácia: %0.2f%%' % (accuracy_score(y_true, score) * 100))\n",
    "print('Matriz de confusão:')\n",
    "print(confusion_matrix(y_true, score))\n",
    "print()\n",
    "print(classification_report(y_true, score, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60459a",
   "metadata": {},
   "source": [
    "# Grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bcb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0706c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
