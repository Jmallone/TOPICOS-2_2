{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98161604",
   "metadata": {},
   "source": [
    "# import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2f5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "\n",
    "rcParams['figure.figsize'] = [16., 5.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efa546",
   "metadata": {},
   "source": [
    "### Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0854ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definições de filtros\n",
    "\n",
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7799f",
   "metadata": {},
   "source": [
    "### Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotData(dirs):\n",
    "#     data = np.load(\"datasets/topicos_cc/\"+dirs)\n",
    "#     data = np.transpose(data, (0, 2, 1))\n",
    "#     print(data.shape)\n",
    "#     data_filtered = butter_notch(data, 60)\n",
    "#     data_filtered = butter_highpass(data_filtered, 5)\n",
    "#     data_filtered = butter_lowpass(data_filtered, 50)\n",
    "#     for i in range(data_filtered.shape[1]):\n",
    "#         plt.plot(data_filtered[0,i,:])\n",
    "#     plt.suptitle(dirs)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8954b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSujeito(dirs):\n",
    "    data = np.load(\"datasets/topicos_cc/\"+dirs)\n",
    "    data = np.transpose(data, (0, 2, 1))\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    \n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d851379",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [ i.split(\"/\")[-1] for i in glob('datasets/topicos_cc/p1*')]\n",
    "data = []\n",
    "for d in dirs:\n",
    "    data.append(loadSujeito(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69570f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3c6022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 4, 1600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58570d7f",
   "metadata": {},
   "source": [
    "### Visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in dirs:\n",
    "#     plotData(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c5b4d",
   "metadata": {},
   "source": [
    "# Concatenando Trials x Movimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df025f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrada = data_array[0]\n",
    "\n",
    "X = []\n",
    "X.append(data_array[1])\n",
    "X.append(data_array[2])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0e6ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 4, 1600), (8, 4, 1600))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#X = data.reshape(24, 4, 1600)\n",
    "X = np.concatenate((np.array(X)), axis=0)\n",
    "\n",
    "X.shape, X_entrada.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba37c5",
   "metadata": {},
   "source": [
    "## Segmentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89833020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "\n",
    "def segmentacao(X):\n",
    "    data = X\n",
    "    step = 11.8\n",
    "    segment = 128\n",
    "    # data = X.reshape(24, 4, 1600)\n",
    "    # print('', data.shape)\n",
    "\n",
    "    n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "    ids = np.arange(n_win) * int(step)\n",
    "\n",
    "    # Janelas do dado no dominio do tempo\n",
    "    chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "    # Janelas do dado no domínio da frequência\n",
    "    _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "    chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "    print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "    print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "    print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "    return chunks_time, chunks_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9744dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (16, 4, 125, 128) - (classes+ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (16, 4, 125, 65) - (classes+ensaios, canais, janelas, linhas)\n",
      "\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (8, 4, 125, 128) - (classes+ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (8, 4, 125, 65) - (classes+ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "chunks_time, chunks_freq = segmentacao(X)\n",
    "print()\n",
    "chunks_time_entrada, chunks_freq_entrada = segmentacao(X_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e27a756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 4, 125, 128), (16, 4, 125, 65))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_time.shape, chunks_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e642d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "701ff37e",
   "metadata": {},
   "source": [
    "## Achar as Janelas\n",
    "O mesmo que a função acima, mas generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import stft\n",
    "\n",
    "# def janela(overl=64):\n",
    "    \n",
    "#     for i in np.arange(1, 128, 0.1):\n",
    "#         step = i\n",
    "#         segment = 128\n",
    "#         data = X.reshape(24, 4, 1600)\n",
    "        \n",
    "#         _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=overl)\n",
    "#         chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "#         window = chunks_freq.shape[2] \n",
    "\n",
    "#         n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "#         ids = np.arange(n_win) * int(step)\n",
    "\n",
    "#         # Janelas do dado no dominio do tempo\n",
    "#         chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "#         time_window = chunks_time.shape[2]\n",
    "            \n",
    "#         if( time_window == window ):\n",
    "#             return step\n",
    "        \n",
    "    \n",
    "# step = janela(overl=64)\n",
    "# print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334267a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_steps = []\n",
    "# for i in [0.5, 0.7, 0.8, 0.9 ]:\n",
    "#     n_step = int(128*i)\n",
    "#     print(n_step)\n",
    "#     step = janela(overl=n_step)\n",
    "#     all_steps.append(step)\n",
    "    \n",
    "# all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba15e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import stft\n",
    "\n",
    "# def time_freq(step):\n",
    "    \n",
    "#     segment = 128\n",
    "#     data = X.reshape(24, 4, 1600)\n",
    "#     print('', data.shape)\n",
    "\n",
    "#     n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "#     ids = np.arange(n_win) * int(step)\n",
    "\n",
    "#     # Janelas do dado no dominio do tempo\n",
    "#     chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "#     # Janelas do dado no domínio da frequência\n",
    "#     _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=64)\n",
    "#     chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "#     print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "#     print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "#     print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "#     return chunks_time, chunks_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf680e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks_time , chunks_freq = time_freq(11.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabb365",
   "metadata": {},
   "source": [
    "## Extração e seleção de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c7c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZC(data, th):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    \n",
    "    for i in range(tamanho-1):\n",
    "        resultado = (data[i] * data[i+1] )\n",
    "        resultado2 = np.abs(data[i] - data[i+1])\n",
    "        if(resultado < 0 ) and (resultado2 > th):\n",
    "            somatoria += 1\n",
    "        \n",
    "    return somatoria\n",
    "\n",
    "def fj(i, sampleRate, tamanho):\n",
    "    return i * sampleRate / (2 * tamanho)\n",
    "\n",
    "def getFMN(data):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    sumPSD = np.sum(PSD(data))\n",
    "    for i in range(tamanho):\n",
    "        somatoria += (fj(i, 41, tamanho) * PSD(data[i]) ) / sumPSD\n",
    "        \n",
    "    return somatoria\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae201a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "def wamp(x, th):\n",
    "    res = np.abs(np.diff(x))\n",
    "    return np.sum(res >= th, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    res = np.abs(np.diff(x))\n",
    "    return np.sum(res, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "def zc(data,threshold):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                fy.append( getZC(data[xx][yy][zz], threshold ) )\n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def fmn(data):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                \n",
    "                fy.append( getFMN(data[xx][yy][zz]) )\n",
    "                \n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def A(w):\n",
    "    return np.abs(w)\n",
    "\n",
    "def getMMNF(data):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    \n",
    "    sumA = np.sum(A(data))\n",
    "    \n",
    "    for i in range(tamanho):\n",
    "        somatoria += (fj(i, 200, tamanho) * A(data[i]) ) / sumA \n",
    "        \n",
    "    return somatoria\n",
    "\n",
    "def mmnf(data):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                \n",
    "                fy.append( getMMNF(data[xx][yy][zz]) )\n",
    "                \n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def logD(data):\n",
    "    from math import e\n",
    "    N = np.prod(data.shape)\n",
    "    \n",
    "    return e ** ( np.sum(np.log10( np.abs(data) ), axis=-1) ) / N\n",
    "\n",
    "def iemg(data):\n",
    "    # tempo\n",
    "    return np.sum(A(data), axis=-1)\n",
    "\n",
    "def dasdv(data):\n",
    "    #tempo\n",
    "    return np.sqrt( np.sum(np.diff(data) ** 2, axis=-1) / (np.prod(data.shape[:-1]) - 1) )\n",
    "\n",
    "def tmx(x, n):\n",
    "    N = np.prod(x.shape[:-1])\n",
    "    return np.abs(np.sum(x ** n, axis=-1) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d388f98",
   "metadata": {},
   "source": [
    "## Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cced9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_filtros(chunks_time, chunks_freq, data):\n",
    "    th = np.median(chunks_time)\n",
    "    #VAR, RMS, WL, TM5 e DASDV\n",
    "    #WL, IEMG, LOGD\n",
    "    final_data = list()\n",
    "    final_data.append(var(chunks_time))\n",
    "    final_data.append(rms(chunks_time))\n",
    "    final_data.append(wamp(chunks_time, th))\n",
    "    final_data.append(logD(chunks_time))\n",
    "    final_data.append(wl(chunks_time))\n",
    "    final_data.append(zc(chunks_time,0))\n",
    "\n",
    "    final_data.append(iemg(chunks_time))\n",
    "    final_data.append(dasdv(chunks_time))\n",
    "    final_data.append(tmx(chunks_time, 3))\n",
    "    final_data.append(tmx(chunks_time, 4))\n",
    "    final_data.append(tmx(chunks_time, 5))\n",
    "\n",
    "    final_data.append(fmd(chunks_freq))\n",
    "    final_data.append(mmdf(chunks_freq))\n",
    "    final_data.append(fmn(chunks_freq))\n",
    "    final_data.append(mmnf(chunks_freq))\n",
    "\n",
    "    f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "    final_data.append(Pxx_den)\n",
    "    final = np.array(final_data)\n",
    "    print(\"SHAPE-: \",final.shape)\n",
    "\n",
    "    return final\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc0b53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE-:  (15, 16, 4, 125)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "th = np.median(chunks_time)\n",
    "\n",
    "\n",
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(wamp(chunks_time, th))\n",
    "final_data.append(logD(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time,0))\n",
    "\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "final_data.append(tmx(chunks_time, 3))\n",
    "final_data.append(tmx(chunks_time, 4))\n",
    "final_data.append(tmx(chunks_time, 5))\n",
    "\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "# f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "# final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "print(\"SHAPE-: \",final.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95a0b522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE-:  (16, 16, 4, 125)\n"
     ]
    }
   ],
   "source": [
    "final = final_filtros(chunks_time, chunks_freq, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd58408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE-:  (16, 8, 4, 125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16, 16, 4, 125), (16, 8, 4, 125))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_entrada = final_filtros(chunks_time_entrada, chunks_freq_entrada, X_entrada)\n",
    "\n",
    "final.shape, final_entrada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4019a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = final.transpose(0, 1, 3, 2)\n",
    "# sh = data.shape\n",
    "\n",
    "# X = data.reshape(sh[0], int(sh[1]/3), 3 * sh[2], sh[3])\n",
    "\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7399aa",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a84b9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# features = list()\n",
    "# for f in X:\n",
    "#     classes = list()\n",
    "#     for c in f:\n",
    "#         C_pca = pca.fit_transform(c)\n",
    "#         classes.append(C_pca)\n",
    "#     features.append(classes)\n",
    "\n",
    "# X_pca = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacdef8",
   "metadata": {},
   "source": [
    "## Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_features(features, features_names, classes_names, ch_1, ch_2):\n",
    "    \n",
    "#     movs = np.arange(len(classes_names))\n",
    "#     markers = [\"o\", \"v\", \"^\", \"P\", \"*\", \"x\", \"X\", \"2\", \"3\", \"1\", 'm', 'L', 'z', 'U', '6']\n",
    "#     for f, feature in enumerate(features):\n",
    "        \n",
    "#         for mov, marker in zip(movs, markers):\n",
    "#             # argumentos: classes, amostras, canal\n",
    "#             plt.scatter(feature[mov, :, ch_1],\n",
    "#                         feature[mov, :, ch_2], marker=marker)\n",
    "\n",
    "#         plt.legend((classes_names), scatterpoints=1, loc='best',\n",
    "#                    ncol=3, fontsize=8)\n",
    "        \n",
    "#         plt.title(features_names[f])\n",
    "#         plt.xlabel('CH{}'.format(ch_1))\n",
    "#         plt.ylabel('CH{}'.format(ch_2))\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'iemg','dasdv','tm3','tm4','tm5', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# classes = [str(item) for item in list(range(8))]\n",
    "# plot_features(X_pca, features_name, classes, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f099f",
   "metadata": {},
   "source": [
    "## Transpose para Selecionar Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2696341b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 4, 125)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape\n",
    "# 24*26 ,9, 4\n",
    "# 24*26 , 10, 4\n",
    "# 24*26 , 15, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ded0f4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 4, 125)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfac4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = final.transpose(1, 3, 2, 0)\n",
    "X = data.reshape(data.shape[0]*data.shape[1], data.shape[2]*data.shape[3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "695a4c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = np.array(list(range(1, 9)) * int(X.shape[0] / 8)) # Antigo\n",
    "\n",
    "y = [ [(i)] * int(X.shape[0] / 8 ) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acc6aa",
   "metadata": {},
   "source": [
    "## Seleção de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb84a3",
   "metadata": {},
   "source": [
    "## Variance Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # teste\n",
    "\n",
    "# data_t = final.transpose(1, 3, 2, 0)\n",
    "# ## X_t = data.reshape(24*26, 9, 4)\n",
    "# ## X_t = data.reshape(24*26, 10, 4)\n",
    "# ## X_t = data.reshape(24*26, 15, 4)\n",
    "# X_t = data.reshape(24*26, 5, 4)\n",
    "\n",
    "# data_t = X_t.transpose(2, 0, 1)\n",
    "# data_t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da98e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# canais = list()\n",
    "\n",
    "# for c in data_t:\n",
    "#     sel = VarianceThreshold(threshold=(.1))\n",
    "#     vt = sel.fit_transform(c)\n",
    "#     canais.append(vt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65210499",
   "metadata": {},
   "source": [
    "### RFE (Por causa do Kernel Linear não iremos utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.svm import SVC\n",
    "# estimator = SVC(kernel=\"linear\")\n",
    "# selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "# selector = selector.fit(X, y)\n",
    "# s = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f20d2",
   "metadata": {},
   "source": [
    "### GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import GenericUnivariateSelect, chi2\n",
    "# transformer = GenericUnivariateSelect(chi2, mode='k_best', param=10)\n",
    "# X_new = transformer.fit_transform(X, y)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# X_new = SelectKBest(k=10).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35750a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757f58e",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d6284f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# X_new_norm = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2119f3",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef5d1447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12166666666666667, 0.7166666666666667)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "def do_svm(X,y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "\n",
    "    clf = SVC(gamma='scale')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "do_svm(X,y), do_svm(X_norm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781c4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e82d8c",
   "metadata": {},
   "source": [
    "# Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         acc = do_svm(X_norm.take(res, axis=1), y)\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_comb = res\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}\")\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# for i in best_comb:\n",
    "#     print(f\" {i} --- {features_name[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d39a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         acc = do_svm(X.take(res, axis=1), y)\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_comb = res\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}\")\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# for i in best_comb:\n",
    "#     print(f\" {i} --- {features_name[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb90af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# best_k = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         for ks in range(1,41):\n",
    "#             X_new = SelectKBest(k=ks).fit_transform(X, y)\n",
    "#             acc = do_svm(X_new_norm.take(res, axis=1), y)\n",
    "\n",
    "#             if acc > best_acc:\n",
    "#                 best_acc = acc\n",
    "#                 best_comb = res\n",
    "#                 best_k = ks\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}, Melhor K: {best_k}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e3cfe",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4e855a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:58:01.347896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 14:58:01.347944: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb16452",
   "metadata": {},
   "source": [
    "## Divisão dos dados em treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "568f8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividindo em conjuntos de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y, test_size=0.3)\n",
    "\n",
    "# treino: 80% dos 80% de treino. Validacao: 20% dos 80% de treino.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, shuffle=None, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3948c1",
   "metadata": {},
   "source": [
    "## Aplicação do algoritmo de MLP e geração dos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5290d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:58:05.063576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-21 14:58:05.063627: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-21 14:58:05.063660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-21 14:58:05.064916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/alunos/a1858351/Documentos/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/home/alunos/a1858351/Documentos/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 2.1966 - accuracy: 0.2439 - val_loss: 1.9828 - val_accuracy: 0.3167\n",
      "Epoch 2/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.7618 - accuracy: 0.4071 - val_loss: 1.6829 - val_accuracy: 0.4095\n",
      "Epoch 3/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.5546 - accuracy: 0.4847 - val_loss: 1.5068 - val_accuracy: 0.5405\n",
      "Epoch 4/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.4394 - accuracy: 0.5633 - val_loss: 1.4502 - val_accuracy: 0.5429\n",
      "Epoch 5/550\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 1.3654 - accuracy: 0.5827 - val_loss: 1.3942 - val_accuracy: 0.5976\n",
      "Epoch 6/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3020 - accuracy: 0.6337 - val_loss: 1.3434 - val_accuracy: 0.6381\n",
      "Epoch 7/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2670 - accuracy: 0.6418 - val_loss: 1.3660 - val_accuracy: 0.6000\n",
      "Epoch 8/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.6531 - val_loss: 1.2764 - val_accuracy: 0.6333\n",
      "Epoch 9/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.6908 - val_loss: 1.2802 - val_accuracy: 0.6238\n",
      "Epoch 10/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1646 - accuracy: 0.6816 - val_loss: 1.2366 - val_accuracy: 0.6738\n",
      "Epoch 11/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1229 - accuracy: 0.7092 - val_loss: 1.2018 - val_accuracy: 0.6643\n",
      "Epoch 12/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1123 - accuracy: 0.7112 - val_loss: 1.2181 - val_accuracy: 0.6857\n",
      "Epoch 13/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.7214 - val_loss: 1.1922 - val_accuracy: 0.7000\n",
      "Epoch 14/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0419 - accuracy: 0.7582 - val_loss: 1.1962 - val_accuracy: 0.7119\n",
      "Epoch 15/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0639 - accuracy: 0.7541 - val_loss: 1.1553 - val_accuracy: 0.6952\n",
      "Epoch 16/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0327 - accuracy: 0.7724 - val_loss: 1.1219 - val_accuracy: 0.7476\n",
      "Epoch 17/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0405 - accuracy: 0.7735 - val_loss: 1.1037 - val_accuracy: 0.7476\n",
      "Epoch 18/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9550 - accuracy: 0.8061 - val_loss: 1.1227 - val_accuracy: 0.7405\n",
      "Epoch 19/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9492 - accuracy: 0.7949 - val_loss: 1.0893 - val_accuracy: 0.7405\n",
      "Epoch 20/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9623 - accuracy: 0.7816 - val_loss: 1.0708 - val_accuracy: 0.7714\n",
      "Epoch 21/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9289 - accuracy: 0.8143 - val_loss: 1.0483 - val_accuracy: 0.7548\n",
      "Epoch 22/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9052 - accuracy: 0.8276 - val_loss: 1.0755 - val_accuracy: 0.7167\n",
      "Epoch 23/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8784 - accuracy: 0.8500 - val_loss: 1.0865 - val_accuracy: 0.7500\n",
      "Epoch 24/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9116 - accuracy: 0.8235 - val_loss: 0.9958 - val_accuracy: 0.7738\n",
      "Epoch 25/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8771 - accuracy: 0.8388 - val_loss: 1.0425 - val_accuracy: 0.7452\n",
      "Epoch 26/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8716 - accuracy: 0.8357 - val_loss: 1.1152 - val_accuracy: 0.7143\n",
      "Epoch 27/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.9115 - accuracy: 0.8214 - val_loss: 1.0249 - val_accuracy: 0.7738\n",
      "Epoch 28/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.8378 - val_loss: 1.0831 - val_accuracy: 0.7405\n",
      "Epoch 29/550\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.8912 - accuracy: 0.8306 - val_loss: 1.0355 - val_accuracy: 0.7500\n",
      "Epoch 30/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.8622 - val_loss: 1.0544 - val_accuracy: 0.7500\n",
      "Epoch 31/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8833 - accuracy: 0.8173 - val_loss: 1.0130 - val_accuracy: 0.7833\n",
      "Epoch 32/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8882 - accuracy: 0.8367 - val_loss: 0.9512 - val_accuracy: 0.7881\n",
      "Epoch 33/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8017 - accuracy: 0.8704 - val_loss: 0.9918 - val_accuracy: 0.7929\n",
      "Epoch 34/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7859 - accuracy: 0.8724 - val_loss: 0.9841 - val_accuracy: 0.7810\n",
      "Epoch 35/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7421 - accuracy: 0.8980 - val_loss: 0.9632 - val_accuracy: 0.7976\n",
      "Epoch 36/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7539 - accuracy: 0.8765 - val_loss: 0.9475 - val_accuracy: 0.7881\n",
      "Epoch 37/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8100 - accuracy: 0.8480 - val_loss: 1.0266 - val_accuracy: 0.7476\n",
      "Epoch 38/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7854 - accuracy: 0.8582 - val_loss: 0.9929 - val_accuracy: 0.7929\n",
      "Epoch 39/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8034 - accuracy: 0.8592 - val_loss: 0.9211 - val_accuracy: 0.7929\n",
      "Epoch 40/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.8806 - val_loss: 0.9320 - val_accuracy: 0.7881\n",
      "Epoch 41/550\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.8929 - val_loss: 0.8960 - val_accuracy: 0.8143\n",
      "Epoch 42/550\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.7388 - accuracy: 0.8786 - val_loss: 0.9697 - val_accuracy: 0.7667\n",
      "Epoch 43/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.8939 - val_loss: 0.9110 - val_accuracy: 0.8024\n",
      "Epoch 44/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.8939 - val_loss: 0.8846 - val_accuracy: 0.8024\n",
      "Epoch 45/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.8776 - val_loss: 0.9285 - val_accuracy: 0.8143\n",
      "Epoch 46/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.8939 - val_loss: 0.8703 - val_accuracy: 0.8381\n",
      "Epoch 47/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.8755 - val_loss: 1.0021 - val_accuracy: 0.7738\n",
      "Epoch 48/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7800 - accuracy: 0.8592 - val_loss: 0.9008 - val_accuracy: 0.8071\n",
      "Epoch 49/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.9061 - val_loss: 0.8999 - val_accuracy: 0.8262\n",
      "Epoch 50/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7424 - accuracy: 0.8714 - val_loss: 0.9424 - val_accuracy: 0.7738\n",
      "Epoch 51/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.8776 - val_loss: 0.8967 - val_accuracy: 0.8190\n",
      "Epoch 52/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.9010 - val_loss: 0.9624 - val_accuracy: 0.7738\n",
      "Epoch 53/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.9061 - val_loss: 0.8798 - val_accuracy: 0.8238\n",
      "Epoch 54/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.9173 - val_loss: 0.8912 - val_accuracy: 0.8190\n",
      "Epoch 55/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.8878 - val_loss: 0.9102 - val_accuracy: 0.8071\n",
      "Epoch 56/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.8959 - val_loss: 0.9066 - val_accuracy: 0.8048\n",
      "Epoch 57/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.9102 - val_loss: 0.8514 - val_accuracy: 0.8452\n",
      "Epoch 58/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.9061 - val_loss: 0.8336 - val_accuracy: 0.8238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.9306 - val_loss: 0.8342 - val_accuracy: 0.8357\n",
      "Epoch 60/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.9163 - val_loss: 0.8605 - val_accuracy: 0.8310\n",
      "Epoch 61/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.9061 - val_loss: 0.8444 - val_accuracy: 0.8048\n",
      "Epoch 62/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.9214 - val_loss: 0.8312 - val_accuracy: 0.8286\n",
      "Epoch 63/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.9347 - val_loss: 0.8256 - val_accuracy: 0.8095\n",
      "Epoch 64/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.8959 - val_loss: 0.9450 - val_accuracy: 0.8000\n",
      "Epoch 65/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.9010 - val_loss: 0.8852 - val_accuracy: 0.8071\n",
      "Epoch 66/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7130 - accuracy: 0.8857 - val_loss: 0.9079 - val_accuracy: 0.8167\n",
      "Epoch 67/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.9071 - val_loss: 0.7936 - val_accuracy: 0.8500\n",
      "Epoch 68/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.9133 - val_loss: 0.8590 - val_accuracy: 0.8476\n",
      "Epoch 69/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.8888 - val_loss: 0.9023 - val_accuracy: 0.7690\n",
      "Epoch 70/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.9153 - val_loss: 0.8392 - val_accuracy: 0.8214\n",
      "Epoch 71/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.9020 - val_loss: 0.8244 - val_accuracy: 0.8333\n",
      "Epoch 72/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.9082 - val_loss: 0.8437 - val_accuracy: 0.8095\n",
      "Epoch 73/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.9071 - val_loss: 0.8917 - val_accuracy: 0.8071\n",
      "Epoch 74/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.9173 - val_loss: 0.8752 - val_accuracy: 0.8214\n",
      "Epoch 75/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.8969 - val_loss: 0.8510 - val_accuracy: 0.8214\n",
      "Epoch 76/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.9041 - val_loss: 0.7852 - val_accuracy: 0.8381\n",
      "Epoch 77/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.9133 - val_loss: 0.8069 - val_accuracy: 0.8429\n",
      "Epoch 78/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.9082 - val_loss: 0.8104 - val_accuracy: 0.8190\n",
      "Epoch 79/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.9286 - val_loss: 0.7727 - val_accuracy: 0.8500\n",
      "Epoch 80/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.9153 - val_loss: 0.8046 - val_accuracy: 0.8190\n",
      "Epoch 81/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.9112 - val_loss: 0.8769 - val_accuracy: 0.8167\n",
      "Epoch 82/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.9000 - val_loss: 0.9756 - val_accuracy: 0.7976\n",
      "Epoch 83/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.8837 - val_loss: 0.8686 - val_accuracy: 0.8214\n",
      "Epoch 84/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.9276 - val_loss: 0.7866 - val_accuracy: 0.8429\n",
      "Epoch 85/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.9204 - val_loss: 0.7702 - val_accuracy: 0.8286\n",
      "Epoch 86/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.8939 - val_loss: 0.8627 - val_accuracy: 0.8214\n",
      "Epoch 87/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.9347 - val_loss: 0.8307 - val_accuracy: 0.8119\n",
      "Epoch 88/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.9214 - val_loss: 0.7471 - val_accuracy: 0.8571\n",
      "Epoch 89/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.9306 - val_loss: 0.7849 - val_accuracy: 0.8500\n",
      "Epoch 90/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.8969 - val_loss: 0.8543 - val_accuracy: 0.8333\n",
      "Epoch 91/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.9153 - val_loss: 0.7957 - val_accuracy: 0.8524\n",
      "Epoch 92/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.9020 - val_loss: 0.9973 - val_accuracy: 0.7571\n",
      "Epoch 93/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.8816 - val_loss: 0.7768 - val_accuracy: 0.8595\n",
      "Epoch 94/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.9378 - val_loss: 0.7373 - val_accuracy: 0.8667\n",
      "Epoch 95/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.9347 - val_loss: 0.7681 - val_accuracy: 0.8548\n",
      "Epoch 96/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.9204 - val_loss: 0.7959 - val_accuracy: 0.8500\n",
      "Epoch 97/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.8959 - val_loss: 0.8659 - val_accuracy: 0.8071\n",
      "Epoch 98/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.9082 - val_loss: 0.9294 - val_accuracy: 0.7810\n",
      "Epoch 99/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.8867 - val_loss: 0.8812 - val_accuracy: 0.8024\n",
      "Epoch 100/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.9071 - val_loss: 0.8204 - val_accuracy: 0.8190\n",
      "Epoch 101/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.9265 - val_loss: 0.8223 - val_accuracy: 0.8143\n",
      "Epoch 102/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.9173 - val_loss: 0.7784 - val_accuracy: 0.8310\n",
      "Epoch 103/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.9122 - val_loss: 0.8870 - val_accuracy: 0.7905\n",
      "Epoch 104/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.9102 - val_loss: 0.8499 - val_accuracy: 0.8095\n",
      "Epoch 105/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.9010 - val_loss: 0.7497 - val_accuracy: 0.8571\n",
      "Epoch 106/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.9347 - val_loss: 0.7934 - val_accuracy: 0.8429\n",
      "Epoch 107/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.9378 - val_loss: 0.7679 - val_accuracy: 0.8524\n",
      "Epoch 108/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.9122 - val_loss: 0.7657 - val_accuracy: 0.8405\n",
      "Epoch 109/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.9224 - val_loss: 0.7674 - val_accuracy: 0.8429\n",
      "Epoch 110/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.9337 - val_loss: 0.7686 - val_accuracy: 0.8429\n",
      "Epoch 111/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.9255 - val_loss: 0.8171 - val_accuracy: 0.8167\n",
      "Epoch 112/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.9112 - val_loss: 0.9138 - val_accuracy: 0.8048\n",
      "Epoch 113/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.9071 - val_loss: 0.8472 - val_accuracy: 0.7929\n",
      "Epoch 114/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.9429 - val_loss: 0.7448 - val_accuracy: 0.8595\n",
      "Epoch 115/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.9296 - val_loss: 0.8805 - val_accuracy: 0.8119\n",
      "Epoch 116/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.9204 - val_loss: 0.7458 - val_accuracy: 0.8524\n",
      "Epoch 117/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.9357 - val_loss: 0.7652 - val_accuracy: 0.8405\n",
      "Epoch 118/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.9449 - val_loss: 0.7461 - val_accuracy: 0.8476\n",
      "Epoch 119/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.9418 - val_loss: 0.7039 - val_accuracy: 0.8595\n",
      "Epoch 120/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.8765 - val_loss: 0.8995 - val_accuracy: 0.8190\n",
      "Epoch 121/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.9092 - val_loss: 0.7653 - val_accuracy: 0.8310\n",
      "Epoch 122/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.8990 - val_loss: 0.8584 - val_accuracy: 0.8143\n",
      "Epoch 123/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.9306 - val_loss: 0.7647 - val_accuracy: 0.8452\n",
      "Epoch 124/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.9235 - val_loss: 0.7614 - val_accuracy: 0.8381\n",
      "Epoch 125/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.9255 - val_loss: 0.8685 - val_accuracy: 0.8048\n",
      "Epoch 126/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.9235 - val_loss: 0.8641 - val_accuracy: 0.8214\n",
      "Epoch 127/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.9367 - val_loss: 0.8384 - val_accuracy: 0.8095\n",
      "Epoch 128/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.9204 - val_loss: 0.8211 - val_accuracy: 0.8190\n",
      "Epoch 129/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.9265 - val_loss: 0.8169 - val_accuracy: 0.8310\n",
      "Epoch 130/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.9327 - val_loss: 0.6912 - val_accuracy: 0.8595\n",
      "Epoch 131/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.9265 - val_loss: 0.7808 - val_accuracy: 0.8452\n",
      "Epoch 132/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.9480 - val_loss: 0.7170 - val_accuracy: 0.8619\n",
      "Epoch 133/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.9327 - val_loss: 0.7634 - val_accuracy: 0.8310\n",
      "Epoch 134/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.9214 - val_loss: 0.8095 - val_accuracy: 0.8452\n",
      "Epoch 135/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.9276 - val_loss: 0.8708 - val_accuracy: 0.8190\n",
      "Epoch 136/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.9173 - val_loss: 0.7550 - val_accuracy: 0.8643\n",
      "Epoch 137/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.9102 - val_loss: 0.7967 - val_accuracy: 0.8167\n",
      "Epoch 138/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.9082 - val_loss: 0.7790 - val_accuracy: 0.8452\n",
      "Epoch 139/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.9255 - val_loss: 0.7432 - val_accuracy: 0.8548\n",
      "Epoch 140/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.9449 - val_loss: 0.7825 - val_accuracy: 0.8190\n",
      "Epoch 141/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.9408 - val_loss: 0.8089 - val_accuracy: 0.8381\n",
      "Epoch 142/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.9449 - val_loss: 0.6885 - val_accuracy: 0.8548\n",
      "Epoch 143/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.9388 - val_loss: 0.7628 - val_accuracy: 0.8452\n",
      "Epoch 144/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.9316 - val_loss: 0.8052 - val_accuracy: 0.8262\n",
      "Epoch 145/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.8765 - val_loss: 0.8588 - val_accuracy: 0.8048\n",
      "Epoch 146/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.8990 - val_loss: 0.8367 - val_accuracy: 0.8333\n",
      "Epoch 147/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.9092 - val_loss: 0.8826 - val_accuracy: 0.8000\n",
      "Epoch 148/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.9224 - val_loss: 0.7700 - val_accuracy: 0.8571\n",
      "Epoch 149/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.9480 - val_loss: 0.7414 - val_accuracy: 0.8500\n",
      "Epoch 150/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.9347 - val_loss: 0.7412 - val_accuracy: 0.8500\n",
      "Epoch 151/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.9490 - val_loss: 0.8311 - val_accuracy: 0.8429\n",
      "Epoch 152/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.9429 - val_loss: 0.6872 - val_accuracy: 0.8690\n",
      "Epoch 153/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.9582 - val_loss: 0.7152 - val_accuracy: 0.8643\n",
      "Epoch 154/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.9520 - val_loss: 0.7704 - val_accuracy: 0.8524\n",
      "Epoch 155/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.9235 - val_loss: 0.7767 - val_accuracy: 0.8405\n",
      "Epoch 156/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.9286 - val_loss: 0.7311 - val_accuracy: 0.8571\n",
      "Epoch 157/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.9571 - val_loss: 0.7187 - val_accuracy: 0.8429\n",
      "Epoch 158/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.9276 - val_loss: 0.8130 - val_accuracy: 0.8167\n",
      "Epoch 159/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.9204 - val_loss: 0.7932 - val_accuracy: 0.8167\n",
      "Epoch 160/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.9153 - val_loss: 0.8097 - val_accuracy: 0.8310\n",
      "Epoch 161/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.9235 - val_loss: 0.7250 - val_accuracy: 0.8548\n",
      "Epoch 162/550\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.9327 - val_loss: 0.7258 - val_accuracy: 0.8452\n",
      "Epoch 163/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.9255 - val_loss: 0.7299 - val_accuracy: 0.8786\n",
      "Epoch 164/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.9306 - val_loss: 0.7793 - val_accuracy: 0.8238\n",
      "Epoch 165/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.9388 - val_loss: 0.7231 - val_accuracy: 0.8571\n",
      "Epoch 166/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.9306 - val_loss: 0.7264 - val_accuracy: 0.8452\n",
      "Epoch 167/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.9418 - val_loss: 0.6782 - val_accuracy: 0.8810\n",
      "Epoch 168/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.9327 - val_loss: 0.7235 - val_accuracy: 0.8524\n",
      "Epoch 169/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.9071 - val_loss: 0.8710 - val_accuracy: 0.8095\n",
      "Epoch 170/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.8898 - val_loss: 0.7869 - val_accuracy: 0.8405\n",
      "Epoch 171/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.9245 - val_loss: 0.7444 - val_accuracy: 0.8405\n",
      "Epoch 172/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.9235 - val_loss: 0.7929 - val_accuracy: 0.8524\n",
      "Epoch 173/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.9418 - val_loss: 0.8600 - val_accuracy: 0.8119\n",
      "Epoch 174/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.9276 - val_loss: 0.7536 - val_accuracy: 0.8357\n",
      "Epoch 175/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.9429 - val_loss: 0.8195 - val_accuracy: 0.8405\n",
      "Epoch 176/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.9429 - val_loss: 0.7490 - val_accuracy: 0.8357\n",
      "Epoch 177/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.9245 - val_loss: 0.7841 - val_accuracy: 0.8238\n",
      "Epoch 178/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.9449 - val_loss: 0.7511 - val_accuracy: 0.8333\n",
      "Epoch 179/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.9449 - val_loss: 0.7489 - val_accuracy: 0.8429\n",
      "Epoch 180/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.9316 - val_loss: 0.7468 - val_accuracy: 0.8429\n",
      "Epoch 181/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.9480 - val_loss: 0.7149 - val_accuracy: 0.8738\n",
      "Epoch 182/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.9622 - val_loss: 0.6339 - val_accuracy: 0.8762\n",
      "Epoch 183/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.9214 - val_loss: 0.7414 - val_accuracy: 0.8476\n",
      "Epoch 184/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.9224 - val_loss: 0.8785 - val_accuracy: 0.8262\n",
      "Epoch 185/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.8980 - val_loss: 0.9560 - val_accuracy: 0.7762\n",
      "Epoch 186/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.9061 - val_loss: 0.9444 - val_accuracy: 0.7905\n",
      "Epoch 187/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.9255 - val_loss: 0.8359 - val_accuracy: 0.8262\n",
      "Epoch 188/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.9378 - val_loss: 0.7202 - val_accuracy: 0.8548\n",
      "Epoch 189/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.9673 - val_loss: 0.7503 - val_accuracy: 0.8452\n",
      "Epoch 190/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.9735 - val_loss: 0.7311 - val_accuracy: 0.8571\n",
      "Epoch 191/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.9541 - val_loss: 0.7236 - val_accuracy: 0.8429\n",
      "Epoch 192/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.9449 - val_loss: 0.7764 - val_accuracy: 0.8262\n",
      "Epoch 193/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.9214 - val_loss: 0.7715 - val_accuracy: 0.8429\n",
      "Epoch 194/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.9357 - val_loss: 0.8746 - val_accuracy: 0.8357\n",
      "Epoch 195/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.9265 - val_loss: 0.7559 - val_accuracy: 0.8167\n",
      "Epoch 196/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.9112 - val_loss: 0.7537 - val_accuracy: 0.8524\n",
      "Epoch 197/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.9204 - val_loss: 0.9074 - val_accuracy: 0.8143\n",
      "Epoch 198/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.9214 - val_loss: 0.7094 - val_accuracy: 0.8357\n",
      "Epoch 199/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.9316 - val_loss: 0.7837 - val_accuracy: 0.8476\n",
      "Epoch 200/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.9163 - val_loss: 0.7680 - val_accuracy: 0.8571\n",
      "Epoch 201/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.9296 - val_loss: 0.7176 - val_accuracy: 0.8548\n",
      "Epoch 202/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.9388 - val_loss: 0.7098 - val_accuracy: 0.8738\n",
      "Epoch 203/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.9459 - val_loss: 0.7512 - val_accuracy: 0.8500\n",
      "Epoch 204/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.9500 - val_loss: 0.7758 - val_accuracy: 0.8429\n",
      "Epoch 205/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.9286 - val_loss: 0.7909 - val_accuracy: 0.8167\n",
      "Epoch 206/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.9163 - val_loss: 0.7742 - val_accuracy: 0.8405\n",
      "Epoch 207/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.9276 - val_loss: 0.7290 - val_accuracy: 0.8571\n",
      "Epoch 208/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.9082 - val_loss: 0.7449 - val_accuracy: 0.8381\n",
      "Epoch 209/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.9286 - val_loss: 0.7030 - val_accuracy: 0.8643\n",
      "Epoch 210/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.9510 - val_loss: 0.7747 - val_accuracy: 0.8571\n",
      "Epoch 211/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.9429 - val_loss: 0.7701 - val_accuracy: 0.8452\n",
      "Epoch 212/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.9429 - val_loss: 0.6558 - val_accuracy: 0.8810\n",
      "Epoch 213/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.9459 - val_loss: 0.8076 - val_accuracy: 0.8357\n",
      "Epoch 214/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.9388 - val_loss: 0.8082 - val_accuracy: 0.8095\n",
      "Epoch 215/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.9296 - val_loss: 0.7933 - val_accuracy: 0.8429\n",
      "Epoch 216/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.9276 - val_loss: 0.7814 - val_accuracy: 0.8833\n",
      "Epoch 217/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.9306 - val_loss: 0.7263 - val_accuracy: 0.8619\n",
      "Epoch 218/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.9439 - val_loss: 0.7053 - val_accuracy: 0.8476\n",
      "Epoch 219/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.9367 - val_loss: 0.7518 - val_accuracy: 0.8262\n",
      "Epoch 220/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.9490 - val_loss: 0.7116 - val_accuracy: 0.8714\n",
      "Epoch 221/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.9245 - val_loss: 0.7159 - val_accuracy: 0.8667\n",
      "Epoch 222/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.9020 - val_loss: 0.7514 - val_accuracy: 0.8310\n",
      "Epoch 223/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.9265 - val_loss: 0.7751 - val_accuracy: 0.8381\n",
      "Epoch 224/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.9051 - val_loss: 0.7021 - val_accuracy: 0.8500\n",
      "Epoch 225/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.9306 - val_loss: 0.7648 - val_accuracy: 0.8310\n",
      "Epoch 226/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.9622 - val_loss: 0.7016 - val_accuracy: 0.8548\n",
      "Epoch 227/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.9500 - val_loss: 0.7720 - val_accuracy: 0.8333\n",
      "Epoch 228/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.9459 - val_loss: 0.6606 - val_accuracy: 0.8762\n",
      "Epoch 229/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.9408 - val_loss: 0.7198 - val_accuracy: 0.8476\n",
      "Epoch 230/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.9449 - val_loss: 0.8445 - val_accuracy: 0.7929\n",
      "Epoch 231/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.9612 - val_loss: 0.6849 - val_accuracy: 0.8714\n",
      "Epoch 232/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.9429 - val_loss: 0.7152 - val_accuracy: 0.8571\n",
      "Epoch 233/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.9571 - val_loss: 0.6772 - val_accuracy: 0.8524\n",
      "Epoch 234/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.9255 - val_loss: 0.8451 - val_accuracy: 0.8190\n",
      "Epoch 235/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.9286 - val_loss: 0.7482 - val_accuracy: 0.8357\n",
      "Epoch 236/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.9173 - val_loss: 0.7511 - val_accuracy: 0.8405\n",
      "Epoch 237/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.9122 - val_loss: 0.8077 - val_accuracy: 0.8381\n",
      "Epoch 238/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.9143 - val_loss: 0.8020 - val_accuracy: 0.8071\n",
      "Epoch 239/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.9347 - val_loss: 0.6705 - val_accuracy: 0.8762\n",
      "Epoch 240/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.9602 - val_loss: 0.6672 - val_accuracy: 0.8786\n",
      "Epoch 241/550\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.9265 - val_loss: 0.8260 - val_accuracy: 0.8476\n",
      "Epoch 242/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.9306 - val_loss: 0.6656 - val_accuracy: 0.8786\n",
      "Epoch 243/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.9388 - val_loss: 0.7317 - val_accuracy: 0.8643\n",
      "Epoch 244/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.9633 - val_loss: 0.6733 - val_accuracy: 0.8714\n",
      "Epoch 245/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.9612 - val_loss: 0.6547 - val_accuracy: 0.8738\n",
      "Epoch 246/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.9306 - val_loss: 0.7667 - val_accuracy: 0.8571\n",
      "Epoch 247/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.9082 - val_loss: 0.7658 - val_accuracy: 0.8452\n",
      "Epoch 248/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.9306 - val_loss: 0.8117 - val_accuracy: 0.8286\n",
      "Epoch 249/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.9429 - val_loss: 0.8857 - val_accuracy: 0.8119\n",
      "Epoch 250/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.9449 - val_loss: 0.6598 - val_accuracy: 0.8714\n",
      "Epoch 251/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.9306 - val_loss: 0.6868 - val_accuracy: 0.8571\n",
      "Epoch 252/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.9418 - val_loss: 0.7414 - val_accuracy: 0.8619\n",
      "Epoch 253/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.9592 - val_loss: 0.6539 - val_accuracy: 0.8929\n",
      "Epoch 254/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.9694 - val_loss: 0.6312 - val_accuracy: 0.8881\n",
      "Epoch 255/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.9449 - val_loss: 0.7772 - val_accuracy: 0.8524\n",
      "Epoch 256/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.8980 - val_loss: 0.7988 - val_accuracy: 0.8381\n",
      "Epoch 257/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.8949 - val_loss: 0.7530 - val_accuracy: 0.8476\n",
      "Epoch 258/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.9520 - val_loss: 0.6407 - val_accuracy: 0.8762\n",
      "Epoch 259/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.9541 - val_loss: 0.7241 - val_accuracy: 0.8619\n",
      "Epoch 260/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.9643 - val_loss: 0.6471 - val_accuracy: 0.8810\n",
      "Epoch 261/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.9398 - val_loss: 0.6699 - val_accuracy: 0.8786\n",
      "Epoch 262/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.9531 - val_loss: 0.7045 - val_accuracy: 0.8524\n",
      "Epoch 263/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.9500 - val_loss: 0.6065 - val_accuracy: 0.8929\n",
      "Epoch 264/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.9612 - val_loss: 0.6853 - val_accuracy: 0.8476\n",
      "Epoch 265/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.9418 - val_loss: 0.6856 - val_accuracy: 0.8619\n",
      "Epoch 266/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.9531 - val_loss: 0.7141 - val_accuracy: 0.8452\n",
      "Epoch 267/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.9224 - val_loss: 0.7379 - val_accuracy: 0.8381\n",
      "Epoch 268/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.9306 - val_loss: 0.7010 - val_accuracy: 0.8500\n",
      "Epoch 269/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.9337 - val_loss: 0.8002 - val_accuracy: 0.8262\n",
      "Epoch 270/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.9255 - val_loss: 0.9156 - val_accuracy: 0.8167\n",
      "Epoch 271/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.9561 - val_loss: 0.6126 - val_accuracy: 0.9000\n",
      "Epoch 272/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.9449 - val_loss: 0.7789 - val_accuracy: 0.8167\n",
      "Epoch 273/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.9102 - val_loss: 0.7979 - val_accuracy: 0.8381\n",
      "Epoch 274/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.8765 - val_loss: 0.7968 - val_accuracy: 0.8143\n",
      "Epoch 275/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.9112 - val_loss: 0.6980 - val_accuracy: 0.8810\n",
      "Epoch 276/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.9469 - val_loss: 0.6912 - val_accuracy: 0.8714\n",
      "Epoch 277/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.9500 - val_loss: 0.6750 - val_accuracy: 0.8476\n",
      "Epoch 278/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.9469 - val_loss: 0.6372 - val_accuracy: 0.8857\n",
      "Epoch 279/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.9714 - val_loss: 0.5923 - val_accuracy: 0.8905\n",
      "Epoch 280/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.9724 - val_loss: 0.6331 - val_accuracy: 0.8833\n",
      "Epoch 281/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.9541 - val_loss: 0.7130 - val_accuracy: 0.8548\n",
      "Epoch 282/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.9561 - val_loss: 0.7091 - val_accuracy: 0.8429\n",
      "Epoch 283/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.9092 - val_loss: 0.6823 - val_accuracy: 0.8714\n",
      "Epoch 284/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.9439 - val_loss: 0.7288 - val_accuracy: 0.8333\n",
      "Epoch 285/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.9337 - val_loss: 0.7043 - val_accuracy: 0.8429\n",
      "Epoch 286/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.9347 - val_loss: 0.7397 - val_accuracy: 0.8357\n",
      "Epoch 287/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.9071 - val_loss: 0.7543 - val_accuracy: 0.8357\n",
      "Epoch 288/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.9337 - val_loss: 0.8286 - val_accuracy: 0.8095\n",
      "Epoch 289/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.8929 - val_loss: 0.8130 - val_accuracy: 0.8286\n",
      "Epoch 290/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.9378 - val_loss: 0.7525 - val_accuracy: 0.8524\n",
      "Epoch 291/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.9429 - val_loss: 0.7088 - val_accuracy: 0.8738\n",
      "Epoch 292/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.9643 - val_loss: 0.6266 - val_accuracy: 0.8952\n",
      "Epoch 293/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.9724 - val_loss: 0.6578 - val_accuracy: 0.8762\n",
      "Epoch 294/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.9724 - val_loss: 0.7882 - val_accuracy: 0.8143\n",
      "Epoch 295/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.9204 - val_loss: 0.7010 - val_accuracy: 0.8548\n",
      "Epoch 296/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.9102 - val_loss: 0.7128 - val_accuracy: 0.8595\n",
      "Epoch 297/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.9255 - val_loss: 0.7986 - val_accuracy: 0.8238\n",
      "Epoch 298/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.9276 - val_loss: 0.6870 - val_accuracy: 0.8714\n",
      "Epoch 299/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.9173 - val_loss: 0.8371 - val_accuracy: 0.8238\n",
      "Epoch 300/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.9286 - val_loss: 0.7660 - val_accuracy: 0.8452\n",
      "Epoch 301/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.9388 - val_loss: 0.7227 - val_accuracy: 0.8452\n",
      "Epoch 302/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.9388 - val_loss: 0.6282 - val_accuracy: 0.8690\n",
      "Epoch 303/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.9663 - val_loss: 0.6914 - val_accuracy: 0.8524\n",
      "Epoch 304/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.9582 - val_loss: 0.6491 - val_accuracy: 0.8476\n",
      "Epoch 305/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.9306 - val_loss: 0.7372 - val_accuracy: 0.8381\n",
      "Epoch 306/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.8990 - val_loss: 0.8560 - val_accuracy: 0.8143\n",
      "Epoch 307/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.9010 - val_loss: 0.7216 - val_accuracy: 0.8405\n",
      "Epoch 308/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.9429 - val_loss: 0.7760 - val_accuracy: 0.8429\n",
      "Epoch 309/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.9367 - val_loss: 0.7569 - val_accuracy: 0.8357\n",
      "Epoch 310/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.9500 - val_loss: 0.6781 - val_accuracy: 0.8762\n",
      "Epoch 311/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.9459 - val_loss: 0.8044 - val_accuracy: 0.8310\n",
      "Epoch 312/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.9398 - val_loss: 0.7542 - val_accuracy: 0.8476\n",
      "Epoch 313/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.9510 - val_loss: 0.6491 - val_accuracy: 0.8833\n",
      "Epoch 314/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.9561 - val_loss: 0.6232 - val_accuracy: 0.8810\n",
      "Epoch 315/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.9663 - val_loss: 0.6296 - val_accuracy: 0.8810\n",
      "Epoch 316/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.9418 - val_loss: 0.8876 - val_accuracy: 0.7929\n",
      "Epoch 317/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.8980 - val_loss: 0.7904 - val_accuracy: 0.8190\n",
      "Epoch 318/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.9235 - val_loss: 0.8649 - val_accuracy: 0.8024\n",
      "Epoch 319/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.9122 - val_loss: 0.8155 - val_accuracy: 0.8310\n",
      "Epoch 320/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.9153 - val_loss: 0.6973 - val_accuracy: 0.8452\n",
      "Epoch 321/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.9510 - val_loss: 0.6320 - val_accuracy: 0.8738\n",
      "Epoch 322/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.9551 - val_loss: 0.6544 - val_accuracy: 0.8690\n",
      "Epoch 323/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.9439 - val_loss: 0.6708 - val_accuracy: 0.8667\n",
      "Epoch 324/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.9531 - val_loss: 0.6341 - val_accuracy: 0.8857\n",
      "Epoch 325/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.9490 - val_loss: 0.7166 - val_accuracy: 0.8429\n",
      "Epoch 326/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.9276 - val_loss: 0.6729 - val_accuracy: 0.8690\n",
      "Epoch 327/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.9224 - val_loss: 0.7828 - val_accuracy: 0.8500\n",
      "Epoch 328/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.9143 - val_loss: 0.7984 - val_accuracy: 0.8262\n",
      "Epoch 329/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.9378 - val_loss: 0.6497 - val_accuracy: 0.8833\n",
      "Epoch 330/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.9439 - val_loss: 0.6309 - val_accuracy: 0.8881\n",
      "Epoch 331/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.9561 - val_loss: 0.7239 - val_accuracy: 0.8381\n",
      "Epoch 332/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.9051 - val_loss: 0.7673 - val_accuracy: 0.8452\n",
      "Epoch 333/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.9602 - val_loss: 0.6583 - val_accuracy: 0.8619\n",
      "Epoch 334/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.9745 - val_loss: 0.6299 - val_accuracy: 0.8929\n",
      "Epoch 335/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.9653 - val_loss: 0.6070 - val_accuracy: 0.8976\n",
      "Epoch 336/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.9265 - val_loss: 0.7403 - val_accuracy: 0.8381\n",
      "Epoch 337/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.9306 - val_loss: 0.7346 - val_accuracy: 0.8429\n",
      "Epoch 338/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.9520 - val_loss: 0.6781 - val_accuracy: 0.8738\n",
      "Epoch 339/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.9418 - val_loss: 0.6679 - val_accuracy: 0.8619\n",
      "Epoch 340/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.9592 - val_loss: 0.6116 - val_accuracy: 0.8762\n",
      "Epoch 341/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.9582 - val_loss: 0.7380 - val_accuracy: 0.8643\n",
      "Epoch 342/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.9194 - val_loss: 0.6869 - val_accuracy: 0.8667\n",
      "Epoch 343/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.9337 - val_loss: 0.7351 - val_accuracy: 0.8500\n",
      "Epoch 344/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.9316 - val_loss: 0.6736 - val_accuracy: 0.8524\n",
      "Epoch 345/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.9265 - val_loss: 0.7543 - val_accuracy: 0.8452\n",
      "Epoch 346/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.9398 - val_loss: 0.6407 - val_accuracy: 0.8810\n",
      "Epoch 347/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.9673 - val_loss: 0.5893 - val_accuracy: 0.9071\n",
      "Epoch 348/550\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.9480 - val_loss: 0.8055 - val_accuracy: 0.8310\n",
      "Epoch 349/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.9459 - val_loss: 0.6591 - val_accuracy: 0.8643\n",
      "Epoch 350/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.9194 - val_loss: 0.6721 - val_accuracy: 0.8500\n",
      "Epoch 351/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.9327 - val_loss: 0.7186 - val_accuracy: 0.8429\n",
      "Epoch 352/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.9582 - val_loss: 0.6091 - val_accuracy: 0.8857\n",
      "Epoch 353/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.9531 - val_loss: 0.5940 - val_accuracy: 0.8833\n",
      "Epoch 354/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.9500 - val_loss: 0.6381 - val_accuracy: 0.8690\n",
      "Epoch 355/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.9541 - val_loss: 0.5096 - val_accuracy: 0.9095\n",
      "Epoch 356/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.9153 - val_loss: 1.1428 - val_accuracy: 0.7286\n",
      "Epoch 357/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.9010 - val_loss: 0.7336 - val_accuracy: 0.8333\n",
      "Epoch 358/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.9276 - val_loss: 0.7411 - val_accuracy: 0.8524\n",
      "Epoch 359/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.9255 - val_loss: 0.6817 - val_accuracy: 0.8619\n",
      "Epoch 360/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.9520 - val_loss: 0.8530 - val_accuracy: 0.8190\n",
      "Epoch 361/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.9449 - val_loss: 0.6628 - val_accuracy: 0.8643\n",
      "Epoch 362/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.9551 - val_loss: 0.6052 - val_accuracy: 0.8762\n",
      "Epoch 363/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.9500 - val_loss: 0.6381 - val_accuracy: 0.8738\n",
      "Epoch 364/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.9490 - val_loss: 0.6571 - val_accuracy: 0.8810\n",
      "Epoch 365/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.9592 - val_loss: 0.6388 - val_accuracy: 0.8786\n",
      "Epoch 366/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.9643 - val_loss: 0.6385 - val_accuracy: 0.8714\n",
      "Epoch 367/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.9327 - val_loss: 0.6667 - val_accuracy: 0.8643\n",
      "Epoch 368/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.9592 - val_loss: 0.7109 - val_accuracy: 0.8643\n",
      "Epoch 369/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.9388 - val_loss: 0.8228 - val_accuracy: 0.8214\n",
      "Epoch 370/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.9347 - val_loss: 0.7227 - val_accuracy: 0.8690\n",
      "Epoch 371/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.9367 - val_loss: 0.6839 - val_accuracy: 0.8738\n",
      "Epoch 372/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.9092 - val_loss: 0.8021 - val_accuracy: 0.8095\n",
      "Epoch 373/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.9357 - val_loss: 0.6768 - val_accuracy: 0.8786\n",
      "Epoch 374/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.9551 - val_loss: 0.6765 - val_accuracy: 0.8833\n",
      "Epoch 375/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.9439 - val_loss: 0.8839 - val_accuracy: 0.7786\n",
      "Epoch 376/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.8898 - val_loss: 0.7140 - val_accuracy: 0.8476\n",
      "Epoch 377/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.8939 - val_loss: 0.7271 - val_accuracy: 0.8548\n",
      "Epoch 378/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.9357 - val_loss: 0.6131 - val_accuracy: 0.8690\n",
      "Epoch 379/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.9663 - val_loss: 0.6522 - val_accuracy: 0.8762\n",
      "Epoch 380/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.9714 - val_loss: 0.6919 - val_accuracy: 0.8595\n",
      "Epoch 381/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.9612 - val_loss: 0.6594 - val_accuracy: 0.8690\n",
      "Epoch 382/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.9541 - val_loss: 0.6989 - val_accuracy: 0.8714\n",
      "Epoch 383/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.9469 - val_loss: 0.6732 - val_accuracy: 0.8762\n",
      "Epoch 384/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.9582 - val_loss: 0.7027 - val_accuracy: 0.8881\n",
      "Epoch 385/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.9500 - val_loss: 0.7194 - val_accuracy: 0.8357\n",
      "Epoch 386/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.9408 - val_loss: 0.7186 - val_accuracy: 0.8667\n",
      "Epoch 387/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.9459 - val_loss: 0.7660 - val_accuracy: 0.8452\n",
      "Epoch 388/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.9429 - val_loss: 0.7902 - val_accuracy: 0.8333\n",
      "Epoch 389/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.9051 - val_loss: 0.9218 - val_accuracy: 0.8095\n",
      "Epoch 390/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.9306 - val_loss: 0.7499 - val_accuracy: 0.8381\n",
      "Epoch 391/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.9316 - val_loss: 0.6307 - val_accuracy: 0.8643\n",
      "Epoch 392/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.9367 - val_loss: 0.7438 - val_accuracy: 0.8452\n",
      "Epoch 393/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.9633 - val_loss: 0.6215 - val_accuracy: 0.8762\n",
      "Epoch 394/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.9673 - val_loss: 0.6533 - val_accuracy: 0.8929\n",
      "Epoch 395/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.9622 - val_loss: 0.6661 - val_accuracy: 0.8595\n",
      "Epoch 396/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.9673 - val_loss: 0.6855 - val_accuracy: 0.8643\n",
      "Epoch 397/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.9592 - val_loss: 0.6748 - val_accuracy: 0.8619\n",
      "Epoch 398/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.9520 - val_loss: 0.6892 - val_accuracy: 0.8738\n",
      "Epoch 399/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.9459 - val_loss: 0.7908 - val_accuracy: 0.8262\n",
      "Epoch 400/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.9194 - val_loss: 0.8613 - val_accuracy: 0.8333\n",
      "Epoch 401/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.9429 - val_loss: 0.9735 - val_accuracy: 0.8214\n",
      "Epoch 402/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.9041 - val_loss: 0.7122 - val_accuracy: 0.8738\n",
      "Epoch 403/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.9439 - val_loss: 0.9118 - val_accuracy: 0.8214\n",
      "Epoch 404/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.8959 - val_loss: 0.7510 - val_accuracy: 0.8500\n",
      "Epoch 405/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.9347 - val_loss: 0.7121 - val_accuracy: 0.8643\n",
      "Epoch 406/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.9459 - val_loss: 0.7011 - val_accuracy: 0.8833\n",
      "Epoch 407/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.9582 - val_loss: 0.6756 - val_accuracy: 0.8619\n",
      "Epoch 408/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.9551 - val_loss: 0.6791 - val_accuracy: 0.8738\n",
      "Epoch 409/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.9490 - val_loss: 0.7511 - val_accuracy: 0.8405\n",
      "Epoch 410/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.9449 - val_loss: 0.6346 - val_accuracy: 0.8905\n",
      "Epoch 411/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.9490 - val_loss: 0.6407 - val_accuracy: 0.8690\n",
      "Epoch 412/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.9418 - val_loss: 0.7779 - val_accuracy: 0.8595\n",
      "Epoch 413/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.9337 - val_loss: 0.6889 - val_accuracy: 0.8524\n",
      "Epoch 414/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.9663 - val_loss: 0.6908 - val_accuracy: 0.8667\n",
      "Epoch 415/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.9469 - val_loss: 0.6091 - val_accuracy: 0.8952\n",
      "Epoch 416/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.9551 - val_loss: 0.6454 - val_accuracy: 0.8881\n",
      "Epoch 417/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.9480 - val_loss: 0.7098 - val_accuracy: 0.8548\n",
      "Epoch 418/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.9622 - val_loss: 0.7021 - val_accuracy: 0.8762\n",
      "Epoch 419/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.9612 - val_loss: 0.7586 - val_accuracy: 0.8762\n",
      "Epoch 420/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.9286 - val_loss: 0.7022 - val_accuracy: 0.8619\n",
      "Epoch 421/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.9204 - val_loss: 0.7168 - val_accuracy: 0.8571\n",
      "Epoch 422/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.9429 - val_loss: 0.6325 - val_accuracy: 0.8786\n",
      "Epoch 423/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.9306 - val_loss: 0.6988 - val_accuracy: 0.8690\n",
      "Epoch 424/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.9296 - val_loss: 0.7501 - val_accuracy: 0.8452\n",
      "Epoch 425/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.8827 - val_loss: 0.7602 - val_accuracy: 0.8333\n",
      "Epoch 426/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.9316 - val_loss: 0.7496 - val_accuracy: 0.8476\n",
      "Epoch 427/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.9510 - val_loss: 0.6234 - val_accuracy: 0.8833\n",
      "Epoch 428/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.9582 - val_loss: 0.5807 - val_accuracy: 0.8929\n",
      "Epoch 429/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.9622 - val_loss: 0.7767 - val_accuracy: 0.8286\n",
      "Epoch 430/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.9735 - val_loss: 0.6943 - val_accuracy: 0.8762\n",
      "Epoch 431/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.9388 - val_loss: 0.6218 - val_accuracy: 0.8762\n",
      "Epoch 432/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.9592 - val_loss: 0.6484 - val_accuracy: 0.8857\n",
      "Epoch 433/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.9398 - val_loss: 0.7398 - val_accuracy: 0.8310\n",
      "Epoch 434/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.8806 - val_loss: 0.8213 - val_accuracy: 0.8119\n",
      "Epoch 435/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.8959 - val_loss: 0.7827 - val_accuracy: 0.8452\n",
      "Epoch 436/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.9347 - val_loss: 0.7395 - val_accuracy: 0.8643\n",
      "Epoch 437/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.9214 - val_loss: 0.8978 - val_accuracy: 0.7976\n",
      "Epoch 438/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.9020 - val_loss: 0.7356 - val_accuracy: 0.8476\n",
      "Epoch 439/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.9520 - val_loss: 0.6804 - val_accuracy: 0.8452\n",
      "Epoch 440/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.9439 - val_loss: 0.6486 - val_accuracy: 0.8952\n",
      "Epoch 441/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.9776 - val_loss: 0.6143 - val_accuracy: 0.8810\n",
      "Epoch 442/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.9592 - val_loss: 0.6769 - val_accuracy: 0.8643\n",
      "Epoch 443/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.9469 - val_loss: 0.6647 - val_accuracy: 0.8548\n",
      "Epoch 444/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.9531 - val_loss: 0.6356 - val_accuracy: 0.8690\n",
      "Epoch 445/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.9724 - val_loss: 0.6853 - val_accuracy: 0.8595\n",
      "Epoch 446/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.9724 - val_loss: 0.6047 - val_accuracy: 0.8976\n",
      "Epoch 447/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.9531 - val_loss: 0.6632 - val_accuracy: 0.8738\n",
      "Epoch 448/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.9541 - val_loss: 0.6881 - val_accuracy: 0.8714\n",
      "Epoch 449/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.9306 - val_loss: 0.6851 - val_accuracy: 0.8762\n",
      "Epoch 450/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.9439 - val_loss: 0.7414 - val_accuracy: 0.8476\n",
      "Epoch 451/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.9173 - val_loss: 0.6738 - val_accuracy: 0.8571\n",
      "Epoch 452/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.9276 - val_loss: 0.7203 - val_accuracy: 0.8786\n",
      "Epoch 453/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.9469 - val_loss: 0.6653 - val_accuracy: 0.8667\n",
      "Epoch 454/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.9673 - val_loss: 0.5980 - val_accuracy: 0.8857\n",
      "Epoch 455/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.9541 - val_loss: 0.6350 - val_accuracy: 0.8619\n",
      "Epoch 456/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.9469 - val_loss: 0.7361 - val_accuracy: 0.8548\n",
      "Epoch 457/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.9276 - val_loss: 0.8729 - val_accuracy: 0.7905\n",
      "Epoch 458/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.9469 - val_loss: 0.6622 - val_accuracy: 0.8738\n",
      "Epoch 459/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.9694 - val_loss: 0.6610 - val_accuracy: 0.8952\n",
      "Epoch 460/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.9571 - val_loss: 0.6473 - val_accuracy: 0.8667\n",
      "Epoch 461/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.9306 - val_loss: 0.6999 - val_accuracy: 0.8571\n",
      "Epoch 462/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.9276 - val_loss: 0.6693 - val_accuracy: 0.8810\n",
      "Epoch 463/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.9265 - val_loss: 0.7834 - val_accuracy: 0.8595\n",
      "Epoch 464/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.9582 - val_loss: 0.6954 - val_accuracy: 0.8810\n",
      "Epoch 465/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.9571 - val_loss: 0.8464 - val_accuracy: 0.8405\n",
      "Epoch 466/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.9531 - val_loss: 0.7577 - val_accuracy: 0.8643\n",
      "Epoch 467/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.9480 - val_loss: 0.6287 - val_accuracy: 0.8786\n",
      "Epoch 468/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.9439 - val_loss: 0.7277 - val_accuracy: 0.8476\n",
      "Epoch 469/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.9112 - val_loss: 0.8399 - val_accuracy: 0.8405\n",
      "Epoch 470/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.9112 - val_loss: 0.8466 - val_accuracy: 0.8429\n",
      "Epoch 471/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.9449 - val_loss: 0.7176 - val_accuracy: 0.8714\n",
      "Epoch 472/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.9541 - val_loss: 0.6819 - val_accuracy: 0.8643\n",
      "Epoch 473/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.9490 - val_loss: 0.6763 - val_accuracy: 0.8738\n",
      "Epoch 474/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.9694 - val_loss: 0.6130 - val_accuracy: 0.8952\n",
      "Epoch 475/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.9643 - val_loss: 0.5979 - val_accuracy: 0.8952\n",
      "Epoch 476/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.9643 - val_loss: 0.5394 - val_accuracy: 0.9119\n",
      "Epoch 477/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.9449 - val_loss: 0.8178 - val_accuracy: 0.8214\n",
      "Epoch 478/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.9010 - val_loss: 0.8535 - val_accuracy: 0.8429\n",
      "Epoch 479/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.9031 - val_loss: 0.8188 - val_accuracy: 0.8238\n",
      "Epoch 480/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.9082 - val_loss: 0.7691 - val_accuracy: 0.8286\n",
      "Epoch 481/550\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.9286 - val_loss: 0.7754 - val_accuracy: 0.8357\n",
      "Epoch 482/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.9449 - val_loss: 0.6858 - val_accuracy: 0.8714\n",
      "Epoch 483/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.9694 - val_loss: 0.6265 - val_accuracy: 0.8833\n",
      "Epoch 484/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.9663 - val_loss: 0.6532 - val_accuracy: 0.8810\n",
      "Epoch 485/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.9408 - val_loss: 0.7288 - val_accuracy: 0.8357\n",
      "Epoch 486/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.9112 - val_loss: 0.7044 - val_accuracy: 0.8452\n",
      "Epoch 487/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.9224 - val_loss: 0.8136 - val_accuracy: 0.8286\n",
      "Epoch 488/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.9214 - val_loss: 0.6570 - val_accuracy: 0.8786\n",
      "Epoch 489/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.9551 - val_loss: 0.7260 - val_accuracy: 0.8762\n",
      "Epoch 490/550\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.9469 - val_loss: 0.7168 - val_accuracy: 0.8714\n",
      "Epoch 491/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.9490 - val_loss: 0.7596 - val_accuracy: 0.8548\n",
      "Epoch 492/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.9296 - val_loss: 0.7414 - val_accuracy: 0.8619\n",
      "Epoch 493/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.9582 - val_loss: 0.6797 - val_accuracy: 0.8762\n",
      "Epoch 494/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.9500 - val_loss: 0.7032 - val_accuracy: 0.8524\n",
      "Epoch 495/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.8857 - val_loss: 0.8984 - val_accuracy: 0.8214\n",
      "Epoch 496/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.9429 - val_loss: 0.6861 - val_accuracy: 0.8714\n",
      "Epoch 497/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.9449 - val_loss: 0.7026 - val_accuracy: 0.8786\n",
      "Epoch 498/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.9694 - val_loss: 0.6638 - val_accuracy: 0.8667\n",
      "Epoch 499/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.9684 - val_loss: 0.6192 - val_accuracy: 0.8881\n",
      "Epoch 500/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.9622 - val_loss: 0.6229 - val_accuracy: 0.9024\n",
      "Epoch 501/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.9582 - val_loss: 0.7112 - val_accuracy: 0.8381\n",
      "Epoch 502/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.9694 - val_loss: 0.6546 - val_accuracy: 0.8762\n",
      "Epoch 503/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.9449 - val_loss: 0.6378 - val_accuracy: 0.8667\n",
      "Epoch 504/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.9582 - val_loss: 0.6673 - val_accuracy: 0.8786\n",
      "Epoch 505/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.9520 - val_loss: 0.8302 - val_accuracy: 0.8429\n",
      "Epoch 506/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.9347 - val_loss: 0.8720 - val_accuracy: 0.8095\n",
      "Epoch 507/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.8857 - val_loss: 0.9008 - val_accuracy: 0.7905\n",
      "Epoch 508/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.9082 - val_loss: 0.8280 - val_accuracy: 0.8238\n",
      "Epoch 509/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.9480 - val_loss: 0.6205 - val_accuracy: 0.8786\n",
      "Epoch 510/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.9755 - val_loss: 0.6587 - val_accuracy: 0.8929\n",
      "Epoch 511/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.9724 - val_loss: 0.7015 - val_accuracy: 0.8762\n",
      "Epoch 512/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.9694 - val_loss: 0.6434 - val_accuracy: 0.8667\n",
      "Epoch 513/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.9663 - val_loss: 0.7131 - val_accuracy: 0.8452\n",
      "Epoch 514/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.9653 - val_loss: 0.7006 - val_accuracy: 0.8690\n",
      "Epoch 515/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.9653 - val_loss: 0.6649 - val_accuracy: 0.8857\n",
      "Epoch 516/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.9602 - val_loss: 0.7929 - val_accuracy: 0.8381\n",
      "Epoch 517/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.9429 - val_loss: 0.6887 - val_accuracy: 0.8714\n",
      "Epoch 518/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.9276 - val_loss: 0.6650 - val_accuracy: 0.8690\n",
      "Epoch 519/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.9214 - val_loss: 0.8775 - val_accuracy: 0.8095\n",
      "Epoch 520/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.8388 - val_loss: 0.8806 - val_accuracy: 0.8071\n",
      "Epoch 521/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.9306 - val_loss: 0.6623 - val_accuracy: 0.8738\n",
      "Epoch 522/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.9520 - val_loss: 0.6727 - val_accuracy: 0.8833\n",
      "Epoch 523/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.9571 - val_loss: 0.7125 - val_accuracy: 0.8571\n",
      "Epoch 524/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.9582 - val_loss: 0.6889 - val_accuracy: 0.8714\n",
      "Epoch 525/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.9684 - val_loss: 0.7011 - val_accuracy: 0.8548\n",
      "Epoch 526/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.9633 - val_loss: 0.6530 - val_accuracy: 0.8619\n",
      "Epoch 527/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.9571 - val_loss: 0.6799 - val_accuracy: 0.8667\n",
      "Epoch 528/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.9316 - val_loss: 0.7701 - val_accuracy: 0.8476\n",
      "Epoch 529/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.9388 - val_loss: 0.6334 - val_accuracy: 0.8619\n",
      "Epoch 530/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.9561 - val_loss: 0.6971 - val_accuracy: 0.8405\n",
      "Epoch 531/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.9265 - val_loss: 0.7978 - val_accuracy: 0.8786\n",
      "Epoch 532/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.9224 - val_loss: 0.7353 - val_accuracy: 0.8619\n",
      "Epoch 533/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.9439 - val_loss: 0.6922 - val_accuracy: 0.8643\n",
      "Epoch 534/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.9327 - val_loss: 0.7373 - val_accuracy: 0.8595\n",
      "Epoch 535/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.9612 - val_loss: 0.5872 - val_accuracy: 0.8929\n",
      "Epoch 536/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.9786 - val_loss: 0.6343 - val_accuracy: 0.8762\n",
      "Epoch 537/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.9388 - val_loss: 0.7356 - val_accuracy: 0.8524\n",
      "Epoch 538/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.9429 - val_loss: 0.7225 - val_accuracy: 0.8667\n",
      "Epoch 539/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.9449 - val_loss: 0.7413 - val_accuracy: 0.8429\n",
      "Epoch 540/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.9643 - val_loss: 0.6589 - val_accuracy: 0.8857\n",
      "Epoch 541/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.9735 - val_loss: 0.6096 - val_accuracy: 0.8786\n",
      "Epoch 542/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.8908 - val_loss: 0.8929 - val_accuracy: 0.8071\n",
      "Epoch 543/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.9296 - val_loss: 0.6632 - val_accuracy: 0.8881\n",
      "Epoch 544/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.9490 - val_loss: 0.6979 - val_accuracy: 0.8810\n",
      "Epoch 545/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.9449 - val_loss: 0.7103 - val_accuracy: 0.8738\n",
      "Epoch 546/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.9235 - val_loss: 0.7531 - val_accuracy: 0.8333\n",
      "Epoch 547/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.9276 - val_loss: 0.7546 - val_accuracy: 0.8405\n",
      "Epoch 548/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.9551 - val_loss: 0.6699 - val_accuracy: 0.8690\n",
      "Epoch 549/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.9622 - val_loss: 0.7068 - val_accuracy: 0.8738\n",
      "Epoch 550/550\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.9735 - val_loss: 0.6680 - val_accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(lr=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=550, batch_size=15,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "#Dro_out, batch_size, epoch, sgd, adam e l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dffb3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step\n",
      "Acurácia: 88.67%\n",
      "Matriz de confusão:\n",
      "[[67  3  0  1  7  0  0  0]\n",
      " [ 0 84  0  2  1  3  3  0]\n",
      " [ 0  0 57  8  0  1  0  0]\n",
      " [ 1  0  0 65  0  0  1  1]\n",
      " [ 2  0  1  1 64  1  1  0]\n",
      " [ 3  4  0  0  5 58  2  2]\n",
      " [ 1  0  0  4  0  0 64  0]\n",
      " [ 2  0  0  3  4  0  0 73]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88158   0.85897   0.87013        78\n",
      "           1    0.92308   0.90323   0.91304        93\n",
      "           2    0.98276   0.86364   0.91935        66\n",
      "           3    0.77381   0.95588   0.85526        68\n",
      "           4    0.79012   0.91429   0.84768        70\n",
      "           5    0.92063   0.78378   0.84672        74\n",
      "           6    0.90141   0.92754   0.91429        69\n",
      "           7    0.96053   0.89024   0.92405        82\n",
      "\n",
      "    accuracy                        0.88667       600\n",
      "   macro avg    0.89174   0.88720   0.88632       600\n",
      "weighted avg    0.89414   0.88667   0.88745       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# score = model.predict_classes(X_test)\n",
    "# y_true = [np.where(x == 1)[0][0] for x in y_test]\n",
    "\n",
    "predict_x=model.predict(X_test) \n",
    "score=np.argmax(predict_x,axis=1)\n",
    "y_true = y_test\n",
    "\n",
    "print('Acurácia: %0.2f%%' % (accuracy_score(y_true, score) * 100))\n",
    "print('Matriz de confusão:')\n",
    "print(confusion_matrix(y_true, score))\n",
    "print()\n",
    "print(classification_report(y_true, score, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60459a",
   "metadata": {},
   "source": [
    "# Grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bcb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0706c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
