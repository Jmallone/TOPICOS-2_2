{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98161604",
   "metadata": {},
   "source": [
    "# import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2f5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "\n",
    "rcParams['figure.figsize'] = [16., 5.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efa546",
   "metadata": {},
   "source": [
    "### Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0854ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definições de filtros\n",
    "\n",
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7799f",
   "metadata": {},
   "source": [
    "### Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93f102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotData(dirs):\n",
    "#     data = np.load(\"datasets/topicos_cc/\"+dirs)\n",
    "#     data = np.transpose(data, (0, 2, 1))\n",
    "#     print(data.shape)\n",
    "#     data_filtered = butter_notch(data, 60)\n",
    "#     data_filtered = butter_highpass(data_filtered, 5)\n",
    "#     data_filtered = butter_lowpass(data_filtered, 50)\n",
    "#     for i in range(data_filtered.shape[1]):\n",
    "#         plt.plot(data_filtered[0,i,:])\n",
    "#     plt.suptitle(dirs)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8954b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSujeito(dirs):\n",
    "    data = np.load(\"datasets/topicos_cc/\"+dirs)\n",
    "    data = np.transpose(data, (0, 2, 1))\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    \n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d851379",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [ i.split(\"/\")[-1] for i in glob('datasets/topicos_cc/p1*')]\n",
    "data = []\n",
    "for d in dirs:\n",
    "    data.append(loadSujeito(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69570f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 4, 1600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58570d7f",
   "metadata": {},
   "source": [
    "### Visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364b6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in dirs:\n",
    "#     plotData(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c5b4d",
   "metadata": {},
   "source": [
    "# Concatenando Trials x Movimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0e6ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4, 1600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#X = data.reshape(24, 4, 1600)\n",
    "X = np.concatenate((data), axis=0)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba37c5",
   "metadata": {},
   "source": [
    "## Segmentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89833020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (24, 4, 125, 128) - (classes+ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (24, 4, 125, 65) - (classes+ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import stft\n",
    "data = X\n",
    "step = 11.8\n",
    "segment = 128\n",
    "# data = X.reshape(24, 4, 1600)\n",
    "# print('', data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * int(step)\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ff37e",
   "metadata": {},
   "source": [
    "## Achar as Janelas\n",
    "O mesmo que a função acima, mas generico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ec698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import stft\n",
    "\n",
    "# def janela(overl=64):\n",
    "    \n",
    "#     for i in np.arange(1, 128, 0.1):\n",
    "#         step = i\n",
    "#         segment = 128\n",
    "#         data = X.reshape(24, 4, 1600)\n",
    "        \n",
    "#         _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=overl)\n",
    "#         chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "#         window = chunks_freq.shape[2] \n",
    "\n",
    "#         n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "#         ids = np.arange(n_win) * int(step)\n",
    "\n",
    "#         # Janelas do dado no dominio do tempo\n",
    "#         chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "#         time_window = chunks_time.shape[2]\n",
    "            \n",
    "#         if( time_window == window ):\n",
    "#             return step\n",
    "        \n",
    "    \n",
    "# step = janela(overl=64)\n",
    "# print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "334267a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_steps = []\n",
    "# for i in [0.5, 0.7, 0.8, 0.9 ]:\n",
    "#     n_step = int(128*i)\n",
    "#     print(n_step)\n",
    "#     step = janela(overl=n_step)\n",
    "#     all_steps.append(step)\n",
    "    \n",
    "# all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba15e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import stft\n",
    "\n",
    "# def time_freq(step):\n",
    "    \n",
    "#     segment = 128\n",
    "#     data = X.reshape(24, 4, 1600)\n",
    "#     print('', data.shape)\n",
    "\n",
    "#     n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "#     ids = np.arange(n_win) * int(step)\n",
    "\n",
    "#     # Janelas do dado no dominio do tempo\n",
    "#     chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "#     # Janelas do dado no domínio da frequência\n",
    "#     _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=64)\n",
    "#     chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "#     print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "#     print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "#     print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "#     return chunks_time, chunks_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf680e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks_time , chunks_freq = time_freq(11.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabb365",
   "metadata": {},
   "source": [
    "## Extração e seleção de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c7c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZC(data, th):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    \n",
    "    for i in range(tamanho-1):\n",
    "        resultado = (data[i] * data[i+1] )\n",
    "        resultado2 = np.abs(data[i] - data[i+1])\n",
    "        if(resultado < 0 ) and (resultado2 > th):\n",
    "            somatoria += 1\n",
    "        \n",
    "    return somatoria\n",
    "\n",
    "def fj(i, sampleRate, tamanho):\n",
    "    return i * sampleRate / (2 * tamanho)\n",
    "\n",
    "def getFMN(data):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    sumPSD = np.sum(PSD(data))\n",
    "    for i in range(tamanho):\n",
    "        somatoria += (fj(i, 41, tamanho) * PSD(data[i]) ) / sumPSD\n",
    "        \n",
    "    return somatoria\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae201a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "def wamp(x, th):\n",
    "    res = np.abs(np.diff(x))\n",
    "    return np.sum(res >= th, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    res = np.abs(np.diff(x))\n",
    "    return np.sum(res, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "def zc(data,threshold):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                fy.append( getZC(data[xx][yy][zz], threshold ) )\n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def fmn(data):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                \n",
    "                fy.append( getFMN(data[xx][yy][zz]) )\n",
    "                \n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def A(w):\n",
    "    return np.abs(w)\n",
    "\n",
    "def getMMNF(data):\n",
    "    tamanho = len(data)\n",
    "    somatoria = 0\n",
    "    \n",
    "    sumA = np.sum(A(data))\n",
    "    \n",
    "    for i in range(tamanho):\n",
    "        somatoria += (fj(i, 200, tamanho) * A(data[i]) ) / sumA \n",
    "        \n",
    "    return somatoria\n",
    "\n",
    "def mmnf(data):\n",
    "    f =[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for xx in range(x):\n",
    "        fx = []\n",
    "        for yy in range(y):\n",
    "            fy = []\n",
    "            for zz in range(z):\n",
    "                \n",
    "                fy.append( getMMNF(data[xx][yy][zz]) )\n",
    "                \n",
    "            fx.append(fy)\n",
    "        f.append(fx)\n",
    "    return np.array(f)\n",
    "\n",
    "def logD(data):\n",
    "    from math import e\n",
    "    N = np.prod(data.shape)\n",
    "    \n",
    "    return e ** ( np.sum(np.log10( np.abs(data) ), axis=-1) ) / N\n",
    "\n",
    "def iemg(data):\n",
    "    # tempo\n",
    "    return np.sum(A(data), axis=-1)\n",
    "\n",
    "def dasdv(data):\n",
    "    #tempo\n",
    "    return np.sqrt( np.sum(np.diff(data) ** 2, axis=-1) / (np.prod(data.shape[:-1]) - 1) )\n",
    "\n",
    "def tmx(x, n):\n",
    "    N = np.prod(x.shape[:-1])\n",
    "    return np.abs(np.sum(x ** n, axis=-1) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d388f98",
   "metadata": {},
   "source": [
    "## Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1cb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.median(chunks_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cced9e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAR, RMS, WL, TM5 e DASDV\n",
    "#WL, IEMG, LOGD\n",
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(wamp(chunks_time, th))\n",
    "final_data.append(logD(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time,0))\n",
    "\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "final_data.append(tmx(chunks_time, 3))\n",
    "final_data.append(tmx(chunks_time, 4))\n",
    "final_data.append(tmx(chunks_time, 5))\n",
    "\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4019a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = final.transpose(0, 1, 3, 2)\n",
    "# sh = data.shape\n",
    "\n",
    "# X = data.reshape(sh[0], int(sh[1]/3), 3 * sh[2], sh[3])\n",
    "\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7399aa",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a84b9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# features = list()\n",
    "# for f in X:\n",
    "#     classes = list()\n",
    "#     for c in f:\n",
    "#         C_pca = pca.fit_transform(c)\n",
    "#         classes.append(C_pca)\n",
    "#     features.append(classes)\n",
    "\n",
    "# X_pca = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3177318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacdef8",
   "metadata": {},
   "source": [
    "## Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d261eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_features(features, features_names, classes_names, ch_1, ch_2):\n",
    "    \n",
    "#     movs = np.arange(len(classes_names))\n",
    "#     markers = [\"o\", \"v\", \"^\", \"P\", \"*\", \"x\", \"X\", \"2\", \"3\", \"1\", 'm', 'L', 'z', 'U', '6']\n",
    "#     for f, feature in enumerate(features):\n",
    "        \n",
    "#         for mov, marker in zip(movs, markers):\n",
    "#             # argumentos: classes, amostras, canal\n",
    "#             plt.scatter(feature[mov, :, ch_1],\n",
    "#                         feature[mov, :, ch_2], marker=marker)\n",
    "\n",
    "#         plt.legend((classes_names), scatterpoints=1, loc='best',\n",
    "#                    ncol=3, fontsize=8)\n",
    "        \n",
    "#         plt.title(features_names[f])\n",
    "#         plt.xlabel('CH{}'.format(ch_1))\n",
    "#         plt.ylabel('CH{}'.format(ch_2))\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1462e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'iemg','dasdv','tm3','tm4','tm5', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# classes = [str(item) for item in list(range(8))]\n",
    "# plot_features(X_pca, features_name, classes, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f099f",
   "metadata": {},
   "source": [
    "## Transpose para Selecionar Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2696341b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape\n",
    "# 24*26 ,9, 4\n",
    "# 24*26 , 10, 4\n",
    "# 24*26 , 15, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfac4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = final.transpose(1, 3, 2, 0)\n",
    "X = data.reshape(data.shape[0]*data.shape[1], data.shape[2]*data.shape[3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "695a4c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = np.array(list(range(1, 9)) * int(X.shape[0] / 8)) # Antigo\n",
    "\n",
    "y = [ [(i)] * int(X.shape[0] / 8 ) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58acc6aa",
   "metadata": {},
   "source": [
    "## Seleção de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb84a3",
   "metadata": {},
   "source": [
    "## Variance Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce3c177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # teste\n",
    "\n",
    "# data_t = final.transpose(1, 3, 2, 0)\n",
    "# ## X_t = data.reshape(24*26, 9, 4)\n",
    "# ## X_t = data.reshape(24*26, 10, 4)\n",
    "# ## X_t = data.reshape(24*26, 15, 4)\n",
    "# X_t = data.reshape(24*26, 5, 4)\n",
    "\n",
    "# data_t = X_t.transpose(2, 0, 1)\n",
    "# data_t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5da98e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# canais = list()\n",
    "\n",
    "# for c in data_t:\n",
    "#     sel = VarianceThreshold(threshold=(.1))\n",
    "#     vt = sel.fit_transform(c)\n",
    "#     canais.append(vt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65210499",
   "metadata": {},
   "source": [
    "### RFE (Por causa do Kernel Linear não iremos utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f2645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.svm import SVC\n",
    "# estimator = SVC(kernel=\"linear\")\n",
    "# selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "# selector = selector.fit(X, y)\n",
    "# s = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f20d2",
   "metadata": {},
   "source": [
    "### GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f58883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28cfdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import GenericUnivariateSelect, chi2\n",
    "# transformer = GenericUnivariateSelect(chi2, mode='k_best', param=10)\n",
    "# X_new = transformer.fit_transform(X, y)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2fa94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# X_new = SelectKBest(k=10).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35750a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757f58e",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d6284f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# X_new_norm = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2119f3",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef5d1447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11, 0.6266666666666667)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "def do_svm(X,y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "\n",
    "    clf = SVC(gamma='scale')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "do_svm(X,y), do_svm(X_norm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781c4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e82d8c",
   "metadata": {},
   "source": [
    "# Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05ffb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         acc = do_svm(X_norm.take(res, axis=1), y)\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_comb = res\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}\")\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# for i in best_comb:\n",
    "#     print(f\" {i} --- {features_name[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77d39a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         acc = do_svm(X.take(res, axis=1), y)\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_comb = res\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}\")\n",
    "\n",
    "# features_name = ('var', 'rms', 'wamp', 'wl', 'zc','logd', 'fmd', 'mmdf', 'fmn', 'mmnf')\n",
    "# for i in best_comb:\n",
    "#     print(f\" {i} --- {features_name[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cb90af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# best_acc = 0\n",
    "# best_comb = 0\n",
    "# best_k = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         for ks in range(1,41):\n",
    "#             X_new = SelectKBest(k=ks).fit_transform(X, y)\n",
    "#             acc = do_svm(X_new_norm.take(res, axis=1), y)\n",
    "\n",
    "#             if acc > best_acc:\n",
    "#                 best_acc = acc\n",
    "#                 best_comb = res\n",
    "#                 best_k = ks\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}, Melhor K: {best_k}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e3cfe",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4e855a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 16:53:33.598175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-02 16:53:33.598212: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb16452",
   "metadata": {},
   "source": [
    "## Divisão dos dados em treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "568f8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividindo em conjuntos de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y, test_size=0.3)\n",
    "\n",
    "# treino: 80% dos 80% de treino. Validacao: 20% dos 80% de treino.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3948c1",
   "metadata": {},
   "source": [
    "## Aplicação do algoritmo de MLP e geração dos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5290d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 16:53:36.032984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-02 16:53:36.033044: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-02 16:53:36.033077: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-02 16:53:36.033477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/alunos/a1858351/Documentos/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/home/alunos/a1858351/Documentos/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 6ms/step - loss: 2.1663 - accuracy: 0.2565 - val_loss: 1.9208 - val_accuracy: 0.3317\n",
      "Epoch 2/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.7929 - accuracy: 0.3524 - val_loss: 1.7206 - val_accuracy: 0.4048\n",
      "Epoch 3/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.6657 - accuracy: 0.4388 - val_loss: 1.6085 - val_accuracy: 0.4619\n",
      "Epoch 4/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.5901 - accuracy: 0.4646 - val_loss: 1.5737 - val_accuracy: 0.4714\n",
      "Epoch 5/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.5425 - accuracy: 0.4830 - val_loss: 1.5470 - val_accuracy: 0.4841\n",
      "Epoch 6/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.4995 - accuracy: 0.5014 - val_loss: 1.5142 - val_accuracy: 0.5032\n",
      "Epoch 7/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.4657 - accuracy: 0.5388 - val_loss: 1.4655 - val_accuracy: 0.5238\n",
      "Epoch 8/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.4073 - accuracy: 0.5578 - val_loss: 1.4752 - val_accuracy: 0.5175\n",
      "Epoch 9/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.4174 - accuracy: 0.5537 - val_loss: 1.4127 - val_accuracy: 0.5587\n",
      "Epoch 10/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.3677 - accuracy: 0.5680 - val_loss: 1.3782 - val_accuracy: 0.5952\n",
      "Epoch 11/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.3474 - accuracy: 0.5803 - val_loss: 1.3321 - val_accuracy: 0.5794\n",
      "Epoch 12/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.3090 - accuracy: 0.6014 - val_loss: 1.3281 - val_accuracy: 0.6206\n",
      "Epoch 13/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.6150 - val_loss: 1.3097 - val_accuracy: 0.6048\n",
      "Epoch 14/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.2548 - accuracy: 0.6327 - val_loss: 1.3137 - val_accuracy: 0.6079\n",
      "Epoch 15/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.2661 - accuracy: 0.6340 - val_loss: 1.2711 - val_accuracy: 0.6270\n",
      "Epoch 16/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.2220 - accuracy: 0.6524 - val_loss: 1.2666 - val_accuracy: 0.6302\n",
      "Epoch 17/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.2116 - accuracy: 0.6490 - val_loss: 1.2720 - val_accuracy: 0.6476\n",
      "Epoch 18/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.2110 - accuracy: 0.6605 - val_loss: 1.2457 - val_accuracy: 0.6508\n",
      "Epoch 19/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.2297 - accuracy: 0.6578 - val_loss: 1.2525 - val_accuracy: 0.6429\n",
      "Epoch 20/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1675 - accuracy: 0.6830 - val_loss: 1.2521 - val_accuracy: 0.6587\n",
      "Epoch 21/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1495 - accuracy: 0.6878 - val_loss: 1.2717 - val_accuracy: 0.6190\n",
      "Epoch 22/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1541 - accuracy: 0.6884 - val_loss: 1.2188 - val_accuracy: 0.6556\n",
      "Epoch 23/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1715 - accuracy: 0.6803 - val_loss: 1.2422 - val_accuracy: 0.6476\n",
      "Epoch 24/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1342 - accuracy: 0.7048 - val_loss: 1.1908 - val_accuracy: 0.6952\n",
      "Epoch 25/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.1236 - accuracy: 0.7184 - val_loss: 1.2003 - val_accuracy: 0.6556\n",
      "Epoch 26/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1025 - accuracy: 0.7156 - val_loss: 1.2031 - val_accuracy: 0.6825\n",
      "Epoch 27/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1027 - accuracy: 0.7150 - val_loss: 1.1777 - val_accuracy: 0.6556\n",
      "Epoch 28/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1057 - accuracy: 0.7048 - val_loss: 1.1888 - val_accuracy: 0.6698\n",
      "Epoch 29/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0735 - accuracy: 0.7224 - val_loss: 1.2356 - val_accuracy: 0.6651\n",
      "Epoch 30/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0873 - accuracy: 0.7272 - val_loss: 1.1959 - val_accuracy: 0.6413\n",
      "Epoch 31/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0377 - accuracy: 0.7395 - val_loss: 1.1893 - val_accuracy: 0.6857\n",
      "Epoch 32/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0576 - accuracy: 0.7279 - val_loss: 1.2161 - val_accuracy: 0.6460\n",
      "Epoch 33/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0472 - accuracy: 0.7313 - val_loss: 1.1176 - val_accuracy: 0.7143\n",
      "Epoch 34/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0462 - accuracy: 0.7422 - val_loss: 1.1437 - val_accuracy: 0.6873\n",
      "Epoch 35/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0144 - accuracy: 0.7531 - val_loss: 1.1252 - val_accuracy: 0.7111\n",
      "Epoch 36/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0079 - accuracy: 0.7449 - val_loss: 1.1591 - val_accuracy: 0.6841\n",
      "Epoch 37/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.7524 - val_loss: 1.1945 - val_accuracy: 0.6762\n",
      "Epoch 38/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0227 - accuracy: 0.7490 - val_loss: 1.2059 - val_accuracy: 0.6794\n",
      "Epoch 39/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0113 - accuracy: 0.7510 - val_loss: 1.1444 - val_accuracy: 0.7048\n",
      "Epoch 40/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.7340 - val_loss: 1.1927 - val_accuracy: 0.6698\n",
      "Epoch 41/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9844 - accuracy: 0.7599 - val_loss: 1.1234 - val_accuracy: 0.6873\n",
      "Epoch 42/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9735 - accuracy: 0.7619 - val_loss: 1.0882 - val_accuracy: 0.7111\n",
      "Epoch 43/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9882 - accuracy: 0.7673 - val_loss: 1.1435 - val_accuracy: 0.7111\n",
      "Epoch 44/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9734 - accuracy: 0.7565 - val_loss: 1.0881 - val_accuracy: 0.7508\n",
      "Epoch 45/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9600 - accuracy: 0.7741 - val_loss: 1.0787 - val_accuracy: 0.7143\n",
      "Epoch 46/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9872 - accuracy: 0.7449 - val_loss: 1.0576 - val_accuracy: 0.7349\n",
      "Epoch 47/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 1.0221 - accuracy: 0.7571 - val_loss: 1.1605 - val_accuracy: 0.6968\n",
      "Epoch 48/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0006 - accuracy: 0.7565 - val_loss: 1.0663 - val_accuracy: 0.7333\n",
      "Epoch 49/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9600 - accuracy: 0.7599 - val_loss: 1.0743 - val_accuracy: 0.7016\n",
      "Epoch 50/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9393 - accuracy: 0.7932 - val_loss: 1.1215 - val_accuracy: 0.6952\n",
      "Epoch 51/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9402 - accuracy: 0.7830 - val_loss: 1.1365 - val_accuracy: 0.6889\n",
      "Epoch 52/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9690 - accuracy: 0.7571 - val_loss: 1.1221 - val_accuracy: 0.6921\n",
      "Epoch 53/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9719 - accuracy: 0.7571 - val_loss: 1.0957 - val_accuracy: 0.7349\n",
      "Epoch 54/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9319 - accuracy: 0.7769 - val_loss: 1.0944 - val_accuracy: 0.6905\n",
      "Epoch 55/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9332 - accuracy: 0.7878 - val_loss: 1.0302 - val_accuracy: 0.7349\n",
      "Epoch 56/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9315 - accuracy: 0.7796 - val_loss: 1.0487 - val_accuracy: 0.7302\n",
      "Epoch 57/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9307 - accuracy: 0.7762 - val_loss: 1.1221 - val_accuracy: 0.7317\n",
      "Epoch 58/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9782 - accuracy: 0.7667 - val_loss: 1.0796 - val_accuracy: 0.7159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9592 - accuracy: 0.7762 - val_loss: 1.0459 - val_accuracy: 0.7397\n",
      "Epoch 60/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9364 - accuracy: 0.7769 - val_loss: 1.1055 - val_accuracy: 0.6746\n",
      "Epoch 61/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9471 - accuracy: 0.7728 - val_loss: 1.2145 - val_accuracy: 0.6746\n",
      "Epoch 62/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9460 - accuracy: 0.7728 - val_loss: 1.1092 - val_accuracy: 0.7222\n",
      "Epoch 63/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9243 - accuracy: 0.7803 - val_loss: 1.0729 - val_accuracy: 0.7190\n",
      "Epoch 64/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9161 - accuracy: 0.7762 - val_loss: 1.0655 - val_accuracy: 0.7286\n",
      "Epoch 65/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9646 - accuracy: 0.7728 - val_loss: 1.0437 - val_accuracy: 0.7381\n",
      "Epoch 66/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9434 - accuracy: 0.7714 - val_loss: 1.0946 - val_accuracy: 0.7032\n",
      "Epoch 67/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9217 - accuracy: 0.7837 - val_loss: 1.0174 - val_accuracy: 0.7349\n",
      "Epoch 68/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.7952 - val_loss: 1.0976 - val_accuracy: 0.7206\n",
      "Epoch 69/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8953 - accuracy: 0.7878 - val_loss: 1.0614 - val_accuracy: 0.7381\n",
      "Epoch 70/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8972 - accuracy: 0.7918 - val_loss: 1.0464 - val_accuracy: 0.7429\n",
      "Epoch 71/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.7884 - val_loss: 1.0573 - val_accuracy: 0.7190\n",
      "Epoch 72/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8975 - accuracy: 0.7966 - val_loss: 1.0263 - val_accuracy: 0.7397\n",
      "Epoch 73/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8812 - accuracy: 0.8020 - val_loss: 1.0167 - val_accuracy: 0.7317\n",
      "Epoch 74/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9626 - accuracy: 0.7701 - val_loss: 1.0371 - val_accuracy: 0.7365\n",
      "Epoch 75/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8840 - accuracy: 0.7986 - val_loss: 1.0542 - val_accuracy: 0.7413\n",
      "Epoch 76/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8802 - accuracy: 0.7918 - val_loss: 1.0286 - val_accuracy: 0.7286\n",
      "Epoch 77/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8544 - accuracy: 0.8068 - val_loss: 1.0329 - val_accuracy: 0.7254\n",
      "Epoch 78/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8943 - accuracy: 0.7796 - val_loss: 1.0710 - val_accuracy: 0.7333\n",
      "Epoch 79/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8744 - accuracy: 0.7986 - val_loss: 1.0330 - val_accuracy: 0.7476\n",
      "Epoch 80/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.8143 - val_loss: 1.0328 - val_accuracy: 0.7397\n",
      "Epoch 81/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8818 - accuracy: 0.7905 - val_loss: 1.0956 - val_accuracy: 0.7063\n",
      "Epoch 82/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9057 - accuracy: 0.7905 - val_loss: 1.0228 - val_accuracy: 0.7413\n",
      "Epoch 83/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8688 - accuracy: 0.8061 - val_loss: 1.0091 - val_accuracy: 0.7540\n",
      "Epoch 84/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8664 - accuracy: 0.8041 - val_loss: 0.9932 - val_accuracy: 0.7524\n",
      "Epoch 85/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8724 - accuracy: 0.8068 - val_loss: 1.0195 - val_accuracy: 0.7222\n",
      "Epoch 86/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8689 - accuracy: 0.7980 - val_loss: 1.0255 - val_accuracy: 0.7556\n",
      "Epoch 87/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.7993 - val_loss: 0.9906 - val_accuracy: 0.7429\n",
      "Epoch 88/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9243 - accuracy: 0.7898 - val_loss: 1.0071 - val_accuracy: 0.7286\n",
      "Epoch 89/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9017 - accuracy: 0.7864 - val_loss: 1.0532 - val_accuracy: 0.7349\n",
      "Epoch 90/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8842 - accuracy: 0.7932 - val_loss: 1.0355 - val_accuracy: 0.7190\n",
      "Epoch 91/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8734 - accuracy: 0.8027 - val_loss: 1.1041 - val_accuracy: 0.7095\n",
      "Epoch 92/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8994 - accuracy: 0.7816 - val_loss: 1.0482 - val_accuracy: 0.7381\n",
      "Epoch 93/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8716 - accuracy: 0.7946 - val_loss: 1.0193 - val_accuracy: 0.7429\n",
      "Epoch 94/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8349 - accuracy: 0.8109 - val_loss: 1.1149 - val_accuracy: 0.7175\n",
      "Epoch 95/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8849 - accuracy: 0.7966 - val_loss: 1.1191 - val_accuracy: 0.6921\n",
      "Epoch 96/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8590 - accuracy: 0.8020 - val_loss: 1.0748 - val_accuracy: 0.7286\n",
      "Epoch 97/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8368 - accuracy: 0.8122 - val_loss: 1.0882 - val_accuracy: 0.7079\n",
      "Epoch 98/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8451 - accuracy: 0.7959 - val_loss: 0.9922 - val_accuracy: 0.7365\n",
      "Epoch 99/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8407 - accuracy: 0.8102 - val_loss: 1.0353 - val_accuracy: 0.7349\n",
      "Epoch 100/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8454 - accuracy: 0.8129 - val_loss: 1.0463 - val_accuracy: 0.7333\n",
      "Epoch 101/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8418 - accuracy: 0.8156 - val_loss: 1.0720 - val_accuracy: 0.7111\n",
      "Epoch 102/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 0.7918 - val_loss: 1.0328 - val_accuracy: 0.7238\n",
      "Epoch 103/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.8048 - val_loss: 1.0019 - val_accuracy: 0.7444\n",
      "Epoch 104/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.8156 - val_loss: 1.0129 - val_accuracy: 0.7397\n",
      "Epoch 105/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8448 - accuracy: 0.8034 - val_loss: 0.9846 - val_accuracy: 0.7556\n",
      "Epoch 106/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8229 - accuracy: 0.8177 - val_loss: 1.0473 - val_accuracy: 0.7508\n",
      "Epoch 107/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8568 - accuracy: 0.8102 - val_loss: 1.1515 - val_accuracy: 0.6778\n",
      "Epoch 108/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8235 - accuracy: 0.8122 - val_loss: 1.0226 - val_accuracy: 0.7254\n",
      "Epoch 109/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8202 - accuracy: 0.8150 - val_loss: 1.0500 - val_accuracy: 0.7302\n",
      "Epoch 110/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8326 - accuracy: 0.8136 - val_loss: 1.0259 - val_accuracy: 0.7302\n",
      "Epoch 111/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8450 - accuracy: 0.8014 - val_loss: 1.0266 - val_accuracy: 0.7524\n",
      "Epoch 112/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8662 - accuracy: 0.7905 - val_loss: 1.1679 - val_accuracy: 0.7143\n",
      "Epoch 113/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8956 - accuracy: 0.7837 - val_loss: 0.9983 - val_accuracy: 0.7333\n",
      "Epoch 114/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8533 - accuracy: 0.8088 - val_loss: 1.0649 - val_accuracy: 0.7317\n",
      "Epoch 115/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8259 - accuracy: 0.8088 - val_loss: 1.0260 - val_accuracy: 0.7397\n",
      "Epoch 116/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.8177 - val_loss: 1.0292 - val_accuracy: 0.7286\n",
      "Epoch 117/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7980 - accuracy: 0.8272 - val_loss: 0.9778 - val_accuracy: 0.7762\n",
      "Epoch 118/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8227 - accuracy: 0.8102 - val_loss: 1.0345 - val_accuracy: 0.7571\n",
      "Epoch 119/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.8170 - val_loss: 1.0330 - val_accuracy: 0.7254\n",
      "Epoch 120/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8424 - accuracy: 0.7973 - val_loss: 1.0905 - val_accuracy: 0.7254\n",
      "Epoch 121/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8486 - accuracy: 0.8054 - val_loss: 1.0248 - val_accuracy: 0.7222\n",
      "Epoch 122/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8495 - accuracy: 0.8034 - val_loss: 1.0297 - val_accuracy: 0.7349\n",
      "Epoch 123/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7931 - accuracy: 0.8259 - val_loss: 1.0492 - val_accuracy: 0.7302\n",
      "Epoch 124/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8395 - accuracy: 0.8034 - val_loss: 1.0495 - val_accuracy: 0.7508\n",
      "Epoch 125/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8638 - accuracy: 0.7905 - val_loss: 1.0202 - val_accuracy: 0.7270\n",
      "Epoch 126/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8374 - accuracy: 0.8218 - val_loss: 1.0116 - val_accuracy: 0.7540\n",
      "Epoch 127/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8148 - accuracy: 0.8286 - val_loss: 1.0369 - val_accuracy: 0.7603\n",
      "Epoch 128/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7992 - accuracy: 0.8238 - val_loss: 1.1247 - val_accuracy: 0.7000\n",
      "Epoch 129/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8116 - accuracy: 0.8150 - val_loss: 0.9660 - val_accuracy: 0.7429\n",
      "Epoch 130/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8177 - accuracy: 0.8054 - val_loss: 1.0166 - val_accuracy: 0.7444\n",
      "Epoch 131/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.8156 - val_loss: 1.1935 - val_accuracy: 0.7032\n",
      "Epoch 132/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8694 - accuracy: 0.8007 - val_loss: 1.0347 - val_accuracy: 0.7397\n",
      "Epoch 133/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.8143 - val_loss: 1.0209 - val_accuracy: 0.7492\n",
      "Epoch 134/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8393 - accuracy: 0.8122 - val_loss: 1.0095 - val_accuracy: 0.7635\n",
      "Epoch 135/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7961 - accuracy: 0.8374 - val_loss: 0.9763 - val_accuracy: 0.7619\n",
      "Epoch 136/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8075 - accuracy: 0.8211 - val_loss: 0.9753 - val_accuracy: 0.7619\n",
      "Epoch 137/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.8048 - val_loss: 1.0113 - val_accuracy: 0.7508\n",
      "Epoch 138/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.8177 - val_loss: 1.0770 - val_accuracy: 0.7190\n",
      "Epoch 139/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.7973 - val_loss: 0.9972 - val_accuracy: 0.7746\n",
      "Epoch 140/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7978 - accuracy: 0.8150 - val_loss: 1.0533 - val_accuracy: 0.7524\n",
      "Epoch 141/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8234 - accuracy: 0.8088 - val_loss: 0.9795 - val_accuracy: 0.7540\n",
      "Epoch 142/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8172 - accuracy: 0.8143 - val_loss: 0.9872 - val_accuracy: 0.7587\n",
      "Epoch 143/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.8150 - val_loss: 0.9844 - val_accuracy: 0.7413\n",
      "Epoch 144/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.8442 - val_loss: 1.1016 - val_accuracy: 0.7317\n",
      "Epoch 145/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.8272 - val_loss: 1.0685 - val_accuracy: 0.7286\n",
      "Epoch 146/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8420 - accuracy: 0.8048 - val_loss: 1.0957 - val_accuracy: 0.7302\n",
      "Epoch 147/550\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.8126 - accuracy: 0.8143 - val_loss: 0.9685 - val_accuracy: 0.7603\n",
      "Epoch 148/550\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.8145 - accuracy: 0.8116 - val_loss: 1.0146 - val_accuracy: 0.7492\n",
      "Epoch 149/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8148 - accuracy: 0.8170 - val_loss: 1.0283 - val_accuracy: 0.7175\n",
      "Epoch 150/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.8075 - val_loss: 0.9992 - val_accuracy: 0.7587\n",
      "Epoch 151/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8539 - accuracy: 0.8020 - val_loss: 1.0964 - val_accuracy: 0.7270\n",
      "Epoch 152/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8266 - accuracy: 0.8293 - val_loss: 0.9961 - val_accuracy: 0.7397\n",
      "Epoch 153/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8118 - accuracy: 0.8293 - val_loss: 0.9987 - val_accuracy: 0.7571\n",
      "Epoch 154/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7885 - accuracy: 0.8252 - val_loss: 0.9949 - val_accuracy: 0.7349\n",
      "Epoch 155/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.8184 - val_loss: 1.0290 - val_accuracy: 0.7429\n",
      "Epoch 156/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.8238 - val_loss: 0.9427 - val_accuracy: 0.7667\n",
      "Epoch 157/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7800 - accuracy: 0.8320 - val_loss: 1.0026 - val_accuracy: 0.7397\n",
      "Epoch 158/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7803 - accuracy: 0.8313 - val_loss: 1.0214 - val_accuracy: 0.7190\n",
      "Epoch 159/550\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7784 - accuracy: 0.8361 - val_loss: 1.0050 - val_accuracy: 0.7619\n",
      "Epoch 160/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.8333 - val_loss: 0.9264 - val_accuracy: 0.7794\n",
      "Epoch 161/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.8361 - val_loss: 0.9878 - val_accuracy: 0.7698\n",
      "Epoch 162/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7768 - accuracy: 0.8313 - val_loss: 1.0441 - val_accuracy: 0.7349\n",
      "Epoch 163/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7758 - accuracy: 0.8401 - val_loss: 1.0469 - val_accuracy: 0.7429\n",
      "Epoch 164/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9320 - accuracy: 0.7837 - val_loss: 1.1865 - val_accuracy: 0.7270\n",
      "Epoch 165/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.8116 - val_loss: 1.0080 - val_accuracy: 0.7413\n",
      "Epoch 166/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.8313 - val_loss: 1.0738 - val_accuracy: 0.7317\n",
      "Epoch 167/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7972 - accuracy: 0.8238 - val_loss: 0.9937 - val_accuracy: 0.7476\n",
      "Epoch 168/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.8565 - val_loss: 0.9885 - val_accuracy: 0.7540\n",
      "Epoch 169/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.8259 - val_loss: 0.9631 - val_accuracy: 0.7603\n",
      "Epoch 170/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7316 - accuracy: 0.8524 - val_loss: 1.1148 - val_accuracy: 0.7333\n",
      "Epoch 171/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.8286 - val_loss: 1.1414 - val_accuracy: 0.7143\n",
      "Epoch 172/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8043 - accuracy: 0.8252 - val_loss: 1.0706 - val_accuracy: 0.7524\n",
      "Epoch 173/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7661 - accuracy: 0.8497 - val_loss: 1.0524 - val_accuracy: 0.7349\n",
      "Epoch 174/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.8109 - val_loss: 1.0288 - val_accuracy: 0.7587\n",
      "Epoch 175/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8236 - accuracy: 0.8129 - val_loss: 1.0177 - val_accuracy: 0.7540\n",
      "Epoch 176/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7858 - accuracy: 0.8422 - val_loss: 0.9547 - val_accuracy: 0.7873\n",
      "Epoch 177/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.8469 - val_loss: 1.0106 - val_accuracy: 0.7476\n",
      "Epoch 178/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7843 - accuracy: 0.8279 - val_loss: 1.0079 - val_accuracy: 0.7302\n",
      "Epoch 179/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.8510 - val_loss: 0.9582 - val_accuracy: 0.7667\n",
      "Epoch 180/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7708 - accuracy: 0.8408 - val_loss: 1.0665 - val_accuracy: 0.7333\n",
      "Epoch 181/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8002 - accuracy: 0.8286 - val_loss: 1.0791 - val_accuracy: 0.7270\n",
      "Epoch 182/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7725 - accuracy: 0.8449 - val_loss: 0.9525 - val_accuracy: 0.7540\n",
      "Epoch 183/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7813 - accuracy: 0.8395 - val_loss: 1.0313 - val_accuracy: 0.7492\n",
      "Epoch 184/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.8408 - val_loss: 0.9326 - val_accuracy: 0.7778\n",
      "Epoch 185/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7271 - accuracy: 0.8605 - val_loss: 0.9891 - val_accuracy: 0.7556\n",
      "Epoch 186/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.8347 - val_loss: 1.0243 - val_accuracy: 0.7413\n",
      "Epoch 187/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7752 - accuracy: 0.8367 - val_loss: 0.9625 - val_accuracy: 0.7381\n",
      "Epoch 188/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7715 - accuracy: 0.8449 - val_loss: 1.0017 - val_accuracy: 0.7635\n",
      "Epoch 189/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.8524 - val_loss: 1.0513 - val_accuracy: 0.7317\n",
      "Epoch 190/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7800 - accuracy: 0.8347 - val_loss: 1.0343 - val_accuracy: 0.7444\n",
      "Epoch 191/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7611 - accuracy: 0.8435 - val_loss: 0.9847 - val_accuracy: 0.7651\n",
      "Epoch 192/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8304 - accuracy: 0.8333 - val_loss: 1.1230 - val_accuracy: 0.7095\n",
      "Epoch 193/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7955 - accuracy: 0.8476 - val_loss: 1.0234 - val_accuracy: 0.7381\n",
      "Epoch 194/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8126 - accuracy: 0.8143 - val_loss: 1.0660 - val_accuracy: 0.7302\n",
      "Epoch 195/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.8633 - val_loss: 0.9682 - val_accuracy: 0.7460\n",
      "Epoch 196/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.8497 - val_loss: 1.1331 - val_accuracy: 0.7206\n",
      "Epoch 197/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7695 - accuracy: 0.8347 - val_loss: 0.9858 - val_accuracy: 0.7730\n",
      "Epoch 198/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7889 - accuracy: 0.8184 - val_loss: 1.0579 - val_accuracy: 0.7381\n",
      "Epoch 199/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.8395 - val_loss: 0.9881 - val_accuracy: 0.7444\n",
      "Epoch 200/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.8551 - val_loss: 1.0172 - val_accuracy: 0.7429\n",
      "Epoch 201/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7883 - accuracy: 0.8184 - val_loss: 1.0207 - val_accuracy: 0.7492\n",
      "Epoch 202/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7694 - accuracy: 0.8395 - val_loss: 0.9864 - val_accuracy: 0.7714\n",
      "Epoch 203/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7723 - accuracy: 0.8259 - val_loss: 1.0255 - val_accuracy: 0.7460\n",
      "Epoch 204/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8013 - accuracy: 0.8211 - val_loss: 1.1329 - val_accuracy: 0.7063\n",
      "Epoch 205/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7605 - accuracy: 0.8395 - val_loss: 0.9480 - val_accuracy: 0.7762\n",
      "Epoch 206/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.8524 - val_loss: 1.0129 - val_accuracy: 0.7603\n",
      "Epoch 207/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7473 - accuracy: 0.8401 - val_loss: 0.9997 - val_accuracy: 0.7571\n",
      "Epoch 208/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.8490 - val_loss: 1.0279 - val_accuracy: 0.7429\n",
      "Epoch 209/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7532 - accuracy: 0.8524 - val_loss: 0.9574 - val_accuracy: 0.7571\n",
      "Epoch 210/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7640 - accuracy: 0.8503 - val_loss: 1.1775 - val_accuracy: 0.7095\n",
      "Epoch 211/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7958 - accuracy: 0.8299 - val_loss: 0.9698 - val_accuracy: 0.7825\n",
      "Epoch 212/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.8599 - val_loss: 0.9933 - val_accuracy: 0.7587\n",
      "Epoch 213/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7514 - accuracy: 0.8429 - val_loss: 0.9779 - val_accuracy: 0.7730\n",
      "Epoch 214/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7676 - accuracy: 0.8306 - val_loss: 1.0580 - val_accuracy: 0.7460\n",
      "Epoch 215/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7776 - accuracy: 0.8483 - val_loss: 1.0899 - val_accuracy: 0.7000\n",
      "Epoch 216/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7602 - accuracy: 0.8435 - val_loss: 0.9495 - val_accuracy: 0.7825\n",
      "Epoch 217/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7120 - accuracy: 0.8599 - val_loss: 0.9305 - val_accuracy: 0.7698\n",
      "Epoch 218/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.8524 - val_loss: 1.0569 - val_accuracy: 0.7349\n",
      "Epoch 219/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.8456 - val_loss: 1.0612 - val_accuracy: 0.7222\n",
      "Epoch 220/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.8435 - val_loss: 0.9500 - val_accuracy: 0.7698\n",
      "Epoch 221/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.8374 - val_loss: 1.0494 - val_accuracy: 0.7429\n",
      "Epoch 222/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.8497 - val_loss: 1.0957 - val_accuracy: 0.7524\n",
      "Epoch 223/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.8408 - val_loss: 1.0747 - val_accuracy: 0.7302\n",
      "Epoch 224/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.8524 - val_loss: 1.0511 - val_accuracy: 0.7492\n",
      "Epoch 225/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7984 - accuracy: 0.8272 - val_loss: 1.0621 - val_accuracy: 0.7508\n",
      "Epoch 226/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7659 - accuracy: 0.8408 - val_loss: 1.0494 - val_accuracy: 0.7365\n",
      "Epoch 227/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7982 - accuracy: 0.8388 - val_loss: 1.0954 - val_accuracy: 0.7270\n",
      "Epoch 228/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7947 - accuracy: 0.8367 - val_loss: 0.9883 - val_accuracy: 0.7619\n",
      "Epoch 229/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.8646 - val_loss: 0.9727 - val_accuracy: 0.7556\n",
      "Epoch 230/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.8619 - val_loss: 1.0026 - val_accuracy: 0.7825\n",
      "Epoch 231/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.8524 - val_loss: 1.1214 - val_accuracy: 0.7111\n",
      "Epoch 232/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.8374 - val_loss: 0.9689 - val_accuracy: 0.7841\n",
      "Epoch 233/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.8490 - val_loss: 0.9740 - val_accuracy: 0.7603\n",
      "Epoch 234/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.8435 - val_loss: 1.1223 - val_accuracy: 0.7016\n",
      "Epoch 235/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7973 - accuracy: 0.8279 - val_loss: 1.1098 - val_accuracy: 0.7206\n",
      "Epoch 236/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7304 - accuracy: 0.8463 - val_loss: 0.9650 - val_accuracy: 0.7778\n",
      "Epoch 237/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.8347 - val_loss: 1.0078 - val_accuracy: 0.7540\n",
      "Epoch 238/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7483 - accuracy: 0.8503 - val_loss: 1.0057 - val_accuracy: 0.7571\n",
      "Epoch 239/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7700 - accuracy: 0.8265 - val_loss: 1.0085 - val_accuracy: 0.7825\n",
      "Epoch 240/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.8388 - val_loss: 1.0526 - val_accuracy: 0.7460\n",
      "Epoch 241/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7690 - accuracy: 0.8395 - val_loss: 1.0858 - val_accuracy: 0.7444\n",
      "Epoch 242/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.8524 - val_loss: 1.0401 - val_accuracy: 0.7556\n",
      "Epoch 243/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7270 - accuracy: 0.8483 - val_loss: 1.0655 - val_accuracy: 0.7397\n",
      "Epoch 244/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7292 - accuracy: 0.8463 - val_loss: 0.9307 - val_accuracy: 0.7841\n",
      "Epoch 245/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8332 - accuracy: 0.8218 - val_loss: 1.1302 - val_accuracy: 0.7254\n",
      "Epoch 246/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.8306 - val_loss: 1.1222 - val_accuracy: 0.7365\n",
      "Epoch 247/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8058 - accuracy: 0.8177 - val_loss: 1.0376 - val_accuracy: 0.7413\n",
      "Epoch 248/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.8714 - val_loss: 1.0488 - val_accuracy: 0.7429\n",
      "Epoch 249/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.8694 - val_loss: 0.9646 - val_accuracy: 0.7778\n",
      "Epoch 250/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7214 - accuracy: 0.8544 - val_loss: 1.1276 - val_accuracy: 0.6857\n",
      "Epoch 251/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.8456 - val_loss: 1.0038 - val_accuracy: 0.7429\n",
      "Epoch 252/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.8626 - val_loss: 1.0888 - val_accuracy: 0.7349\n",
      "Epoch 253/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.8537 - val_loss: 1.0405 - val_accuracy: 0.7714\n",
      "Epoch 254/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8117 - accuracy: 0.8259 - val_loss: 1.1170 - val_accuracy: 0.7254\n",
      "Epoch 255/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.8381 - val_loss: 1.0316 - val_accuracy: 0.7556\n",
      "Epoch 256/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.8442 - val_loss: 1.0109 - val_accuracy: 0.7651\n",
      "Epoch 257/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.8599 - val_loss: 0.9953 - val_accuracy: 0.7714\n",
      "Epoch 258/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.8531 - val_loss: 1.0210 - val_accuracy: 0.7413\n",
      "Epoch 259/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.8524 - val_loss: 0.9868 - val_accuracy: 0.7556\n",
      "Epoch 260/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7456 - accuracy: 0.8463 - val_loss: 1.1149 - val_accuracy: 0.7302\n",
      "Epoch 261/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7990 - accuracy: 0.8272 - val_loss: 0.9902 - val_accuracy: 0.7587\n",
      "Epoch 262/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.8449 - val_loss: 0.9495 - val_accuracy: 0.7746\n",
      "Epoch 263/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.8741 - val_loss: 0.9873 - val_accuracy: 0.7524\n",
      "Epoch 264/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7231 - accuracy: 0.8517 - val_loss: 1.0177 - val_accuracy: 0.7603\n",
      "Epoch 265/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7237 - accuracy: 0.8544 - val_loss: 0.9589 - val_accuracy: 0.7635\n",
      "Epoch 266/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.8687 - val_loss: 1.0349 - val_accuracy: 0.7619\n",
      "Epoch 267/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7589 - accuracy: 0.8354 - val_loss: 1.2312 - val_accuracy: 0.6968\n",
      "Epoch 268/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.8306 - val_loss: 1.0401 - val_accuracy: 0.7492\n",
      "Epoch 269/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7501 - accuracy: 0.8415 - val_loss: 1.0636 - val_accuracy: 0.7286\n",
      "Epoch 270/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.8653 - val_loss: 1.0105 - val_accuracy: 0.7429\n",
      "Epoch 271/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.8599 - val_loss: 1.0639 - val_accuracy: 0.7286\n",
      "Epoch 272/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7922 - accuracy: 0.8279 - val_loss: 1.0098 - val_accuracy: 0.7365\n",
      "Epoch 273/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7595 - accuracy: 0.8422 - val_loss: 1.1823 - val_accuracy: 0.6889\n",
      "Epoch 274/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7741 - accuracy: 0.8361 - val_loss: 1.0870 - val_accuracy: 0.7381\n",
      "Epoch 275/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8459 - accuracy: 0.8224 - val_loss: 1.0522 - val_accuracy: 0.7587\n",
      "Epoch 276/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7998 - accuracy: 0.8299 - val_loss: 1.0286 - val_accuracy: 0.7587\n",
      "Epoch 277/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.8503 - val_loss: 1.1083 - val_accuracy: 0.7556\n",
      "Epoch 278/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.8361 - val_loss: 1.0153 - val_accuracy: 0.7540\n",
      "Epoch 279/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.8680 - val_loss: 0.9895 - val_accuracy: 0.7778\n",
      "Epoch 280/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.8646 - val_loss: 0.9876 - val_accuracy: 0.7778\n",
      "Epoch 281/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.8864 - val_loss: 0.9712 - val_accuracy: 0.7460\n",
      "Epoch 282/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.8517 - val_loss: 0.9500 - val_accuracy: 0.7857\n",
      "Epoch 283/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7157 - accuracy: 0.8531 - val_loss: 1.0559 - val_accuracy: 0.7381\n",
      "Epoch 284/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.8401 - val_loss: 0.9895 - val_accuracy: 0.7603\n",
      "Epoch 285/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7238 - accuracy: 0.8510 - val_loss: 0.9877 - val_accuracy: 0.7651\n",
      "Epoch 286/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.8483 - val_loss: 1.0158 - val_accuracy: 0.7730\n",
      "Epoch 287/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.8531 - val_loss: 1.0447 - val_accuracy: 0.7397\n",
      "Epoch 288/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.8497 - val_loss: 1.0341 - val_accuracy: 0.7667\n",
      "Epoch 289/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.8667 - val_loss: 0.9839 - val_accuracy: 0.7683\n",
      "Epoch 290/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.8660 - val_loss: 1.0146 - val_accuracy: 0.7556\n",
      "Epoch 291/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.8667 - val_loss: 1.0251 - val_accuracy: 0.7651\n",
      "Epoch 292/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.8503 - val_loss: 1.2970 - val_accuracy: 0.6952\n",
      "Epoch 293/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.8381 - val_loss: 1.0875 - val_accuracy: 0.7365\n",
      "Epoch 294/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7742 - accuracy: 0.8211 - val_loss: 1.1630 - val_accuracy: 0.7270\n",
      "Epoch 295/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.8367 - val_loss: 0.9751 - val_accuracy: 0.7714\n",
      "Epoch 296/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.8701 - val_loss: 1.0281 - val_accuracy: 0.7429\n",
      "Epoch 297/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.8599 - val_loss: 1.1144 - val_accuracy: 0.7587\n",
      "Epoch 298/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.8571 - val_loss: 1.1089 - val_accuracy: 0.7333\n",
      "Epoch 299/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.8735 - val_loss: 1.0913 - val_accuracy: 0.7698\n",
      "Epoch 300/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.8415 - val_loss: 1.0747 - val_accuracy: 0.7365\n",
      "Epoch 301/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7682 - accuracy: 0.8361 - val_loss: 1.0614 - val_accuracy: 0.7317\n",
      "Epoch 302/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.8381 - val_loss: 1.0225 - val_accuracy: 0.7492\n",
      "Epoch 303/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7224 - accuracy: 0.8558 - val_loss: 0.9955 - val_accuracy: 0.7635\n",
      "Epoch 304/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.8558 - val_loss: 1.0347 - val_accuracy: 0.7730\n",
      "Epoch 305/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.8762 - val_loss: 1.0235 - val_accuracy: 0.7492\n",
      "Epoch 306/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.8673 - val_loss: 1.0019 - val_accuracy: 0.7698\n",
      "Epoch 307/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.8429 - val_loss: 1.0676 - val_accuracy: 0.7492\n",
      "Epoch 308/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.8279 - val_loss: 1.0482 - val_accuracy: 0.7714\n",
      "Epoch 309/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.8571 - val_loss: 0.9602 - val_accuracy: 0.7460\n",
      "Epoch 310/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7271 - accuracy: 0.8510 - val_loss: 1.0627 - val_accuracy: 0.7619\n",
      "Epoch 311/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7443 - accuracy: 0.8401 - val_loss: 1.0934 - val_accuracy: 0.7492\n",
      "Epoch 312/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7719 - accuracy: 0.8422 - val_loss: 1.0017 - val_accuracy: 0.7444\n",
      "Epoch 313/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.8599 - val_loss: 1.0051 - val_accuracy: 0.7508\n",
      "Epoch 314/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7461 - accuracy: 0.8388 - val_loss: 1.0195 - val_accuracy: 0.7508\n",
      "Epoch 315/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.8646 - val_loss: 1.0049 - val_accuracy: 0.7460\n",
      "Epoch 316/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.8687 - val_loss: 1.0111 - val_accuracy: 0.7651\n",
      "Epoch 317/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.8524 - val_loss: 1.0373 - val_accuracy: 0.7508\n",
      "Epoch 318/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.8646 - val_loss: 0.9678 - val_accuracy: 0.7762\n",
      "Epoch 319/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.8667 - val_loss: 0.9755 - val_accuracy: 0.7635\n",
      "Epoch 320/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.8544 - val_loss: 1.1999 - val_accuracy: 0.7222\n",
      "Epoch 321/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8639 - accuracy: 0.8109 - val_loss: 1.2392 - val_accuracy: 0.6857\n",
      "Epoch 322/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8062 - accuracy: 0.8170 - val_loss: 1.1557 - val_accuracy: 0.7333\n",
      "Epoch 323/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7402 - accuracy: 0.8463 - val_loss: 1.0222 - val_accuracy: 0.7492\n",
      "Epoch 324/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.8524 - val_loss: 1.0489 - val_accuracy: 0.7746\n",
      "Epoch 325/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7521 - accuracy: 0.8497 - val_loss: 1.1184 - val_accuracy: 0.7587\n",
      "Epoch 326/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.8551 - val_loss: 1.0089 - val_accuracy: 0.7746\n",
      "Epoch 327/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.8565 - val_loss: 0.9507 - val_accuracy: 0.7667\n",
      "Epoch 328/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.8714 - val_loss: 0.9451 - val_accuracy: 0.7524\n",
      "Epoch 329/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.8721 - val_loss: 0.9968 - val_accuracy: 0.7778\n",
      "Epoch 330/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.8551 - val_loss: 0.9926 - val_accuracy: 0.7413\n",
      "Epoch 331/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.8483 - val_loss: 1.0892 - val_accuracy: 0.7429\n",
      "Epoch 332/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.8374 - val_loss: 0.9462 - val_accuracy: 0.7762\n",
      "Epoch 333/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7160 - accuracy: 0.8578 - val_loss: 0.9980 - val_accuracy: 0.7810\n",
      "Epoch 334/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.8565 - val_loss: 0.9866 - val_accuracy: 0.7714\n",
      "Epoch 335/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7265 - accuracy: 0.8565 - val_loss: 1.2660 - val_accuracy: 0.6937\n",
      "Epoch 336/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8252 - accuracy: 0.8190 - val_loss: 1.0269 - val_accuracy: 0.7571\n",
      "Epoch 337/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.8544 - val_loss: 1.0092 - val_accuracy: 0.7508\n",
      "Epoch 338/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.8619 - val_loss: 1.0066 - val_accuracy: 0.7619\n",
      "Epoch 339/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.8673 - val_loss: 1.0090 - val_accuracy: 0.7651\n",
      "Epoch 340/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.8612 - val_loss: 0.9461 - val_accuracy: 0.7889\n",
      "Epoch 341/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.8565 - val_loss: 1.1333 - val_accuracy: 0.7524\n",
      "Epoch 342/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.8483 - val_loss: 0.9609 - val_accuracy: 0.7683\n",
      "Epoch 343/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.8429 - val_loss: 1.0116 - val_accuracy: 0.7444\n",
      "Epoch 344/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.8272 - val_loss: 1.0694 - val_accuracy: 0.7317\n",
      "Epoch 345/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7649 - accuracy: 0.8333 - val_loss: 1.0674 - val_accuracy: 0.7508\n",
      "Epoch 346/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.8592 - val_loss: 0.9867 - val_accuracy: 0.7587\n",
      "Epoch 347/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7559 - accuracy: 0.8320 - val_loss: 1.1048 - val_accuracy: 0.7032\n",
      "Epoch 348/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.8435 - val_loss: 1.0588 - val_accuracy: 0.7651\n",
      "Epoch 349/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.8721 - val_loss: 1.0666 - val_accuracy: 0.7429\n",
      "Epoch 350/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.8667 - val_loss: 1.0753 - val_accuracy: 0.7476\n",
      "Epoch 351/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.8796 - val_loss: 1.0890 - val_accuracy: 0.7222\n",
      "Epoch 352/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.8626 - val_loss: 0.9982 - val_accuracy: 0.7540\n",
      "Epoch 353/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.8469 - val_loss: 1.0549 - val_accuracy: 0.7571\n",
      "Epoch 354/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.8517 - val_loss: 1.0044 - val_accuracy: 0.7714\n",
      "Epoch 355/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.8605 - val_loss: 1.0597 - val_accuracy: 0.7571\n",
      "Epoch 356/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.8585 - val_loss: 1.0255 - val_accuracy: 0.7603\n",
      "Epoch 357/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.8694 - val_loss: 0.9859 - val_accuracy: 0.7587\n",
      "Epoch 358/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.8653 - val_loss: 1.0428 - val_accuracy: 0.7810\n",
      "Epoch 359/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7103 - accuracy: 0.8510 - val_loss: 1.0067 - val_accuracy: 0.7587\n",
      "Epoch 360/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.8687 - val_loss: 1.0063 - val_accuracy: 0.7635\n",
      "Epoch 361/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.8565 - val_loss: 1.0698 - val_accuracy: 0.7365\n",
      "Epoch 362/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7774 - accuracy: 0.8340 - val_loss: 1.0649 - val_accuracy: 0.7381\n",
      "Epoch 363/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.8395 - val_loss: 1.1086 - val_accuracy: 0.7444\n",
      "Epoch 364/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.8633 - val_loss: 1.0302 - val_accuracy: 0.7444\n",
      "Epoch 365/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.8701 - val_loss: 1.0824 - val_accuracy: 0.7571\n",
      "Epoch 366/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8154 - accuracy: 0.8231 - val_loss: 1.0314 - val_accuracy: 0.7556\n",
      "Epoch 367/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.8619 - val_loss: 1.0172 - val_accuracy: 0.7683\n",
      "Epoch 368/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7153 - accuracy: 0.8537 - val_loss: 1.0748 - val_accuracy: 0.7206\n",
      "Epoch 369/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7171 - accuracy: 0.8592 - val_loss: 1.0096 - val_accuracy: 0.7302\n",
      "Epoch 370/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.8558 - val_loss: 1.1435 - val_accuracy: 0.6984\n",
      "Epoch 371/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.8612 - val_loss: 1.0368 - val_accuracy: 0.7492\n",
      "Epoch 372/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.8558 - val_loss: 0.9853 - val_accuracy: 0.7857\n",
      "Epoch 373/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.8687 - val_loss: 1.0803 - val_accuracy: 0.7508\n",
      "Epoch 374/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.8694 - val_loss: 1.1029 - val_accuracy: 0.7413\n",
      "Epoch 375/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.8463 - val_loss: 0.9649 - val_accuracy: 0.7587\n",
      "Epoch 376/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7274 - accuracy: 0.8476 - val_loss: 1.0309 - val_accuracy: 0.7619\n",
      "Epoch 377/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.8701 - val_loss: 1.0138 - val_accuracy: 0.7556\n",
      "Epoch 378/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7044 - accuracy: 0.8585 - val_loss: 1.0491 - val_accuracy: 0.7746\n",
      "Epoch 379/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.8748 - val_loss: 1.1090 - val_accuracy: 0.7381\n",
      "Epoch 380/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7060 - accuracy: 0.8537 - val_loss: 0.9907 - val_accuracy: 0.7905\n",
      "Epoch 381/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7324 - accuracy: 0.8531 - val_loss: 1.1193 - val_accuracy: 0.7190\n",
      "Epoch 382/550\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7751 - accuracy: 0.8136 - val_loss: 1.1089 - val_accuracy: 0.7429\n",
      "Epoch 383/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7703 - accuracy: 0.8279 - val_loss: 1.0873 - val_accuracy: 0.7603\n",
      "Epoch 384/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7304 - accuracy: 0.8456 - val_loss: 1.0610 - val_accuracy: 0.7302\n",
      "Epoch 385/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.8612 - val_loss: 1.1179 - val_accuracy: 0.7238\n",
      "Epoch 386/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.8340 - val_loss: 1.0593 - val_accuracy: 0.7683\n",
      "Epoch 387/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7815 - accuracy: 0.8238 - val_loss: 1.0675 - val_accuracy: 0.7270\n",
      "Epoch 388/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7691 - accuracy: 0.8442 - val_loss: 1.0232 - val_accuracy: 0.7413\n",
      "Epoch 389/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.8599 - val_loss: 0.9515 - val_accuracy: 0.7778\n",
      "Epoch 390/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.8599 - val_loss: 1.0195 - val_accuracy: 0.7429\n",
      "Epoch 391/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.8687 - val_loss: 0.9510 - val_accuracy: 0.7730\n",
      "Epoch 392/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.8565 - val_loss: 1.0399 - val_accuracy: 0.7492\n",
      "Epoch 393/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.8571 - val_loss: 1.0245 - val_accuracy: 0.7667\n",
      "Epoch 394/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.8469 - val_loss: 1.2325 - val_accuracy: 0.6810\n",
      "Epoch 395/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7677 - accuracy: 0.8320 - val_loss: 1.0298 - val_accuracy: 0.7667\n",
      "Epoch 396/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.8599 - val_loss: 0.9713 - val_accuracy: 0.7524\n",
      "Epoch 397/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7197 - accuracy: 0.8483 - val_loss: 0.9865 - val_accuracy: 0.7698\n",
      "Epoch 398/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7093 - accuracy: 0.8680 - val_loss: 1.0402 - val_accuracy: 0.7460\n",
      "Epoch 399/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.8524 - val_loss: 0.9796 - val_accuracy: 0.7635\n",
      "Epoch 400/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.8626 - val_loss: 1.0407 - val_accuracy: 0.7587\n",
      "Epoch 401/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.8646 - val_loss: 0.9766 - val_accuracy: 0.7667\n",
      "Epoch 402/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.8544 - val_loss: 1.1276 - val_accuracy: 0.7397\n",
      "Epoch 403/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.8490 - val_loss: 0.9782 - val_accuracy: 0.7683\n",
      "Epoch 404/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7327 - accuracy: 0.8422 - val_loss: 1.0953 - val_accuracy: 0.7302\n",
      "Epoch 405/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.8510 - val_loss: 0.9234 - val_accuracy: 0.7889\n",
      "Epoch 406/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.8714 - val_loss: 0.9534 - val_accuracy: 0.7730\n",
      "Epoch 407/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.8422 - val_loss: 1.2155 - val_accuracy: 0.7190\n",
      "Epoch 408/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.8442 - val_loss: 1.0878 - val_accuracy: 0.7270\n",
      "Epoch 409/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7257 - accuracy: 0.8401 - val_loss: 1.0726 - val_accuracy: 0.7238\n",
      "Epoch 410/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.8565 - val_loss: 1.0784 - val_accuracy: 0.7349\n",
      "Epoch 411/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.8429 - val_loss: 0.9868 - val_accuracy: 0.7746\n",
      "Epoch 412/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.8660 - val_loss: 1.0384 - val_accuracy: 0.7556\n",
      "Epoch 413/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.8442 - val_loss: 0.9139 - val_accuracy: 0.7889\n",
      "Epoch 414/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.8646 - val_loss: 0.9555 - val_accuracy: 0.7556\n",
      "Epoch 415/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.8585 - val_loss: 1.0184 - val_accuracy: 0.7540\n",
      "Epoch 416/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.8435 - val_loss: 1.1542 - val_accuracy: 0.6952\n",
      "Epoch 417/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7559 - accuracy: 0.8408 - val_loss: 1.0605 - val_accuracy: 0.7349\n",
      "Epoch 418/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.8660 - val_loss: 1.0242 - val_accuracy: 0.7444\n",
      "Epoch 419/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7443 - accuracy: 0.8381 - val_loss: 1.0039 - val_accuracy: 0.7762\n",
      "Epoch 420/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.8626 - val_loss: 1.0151 - val_accuracy: 0.7635\n",
      "Epoch 421/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.8653 - val_loss: 0.9510 - val_accuracy: 0.7587\n",
      "Epoch 422/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.8537 - val_loss: 1.0510 - val_accuracy: 0.7476\n",
      "Epoch 423/550\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7132 - accuracy: 0.8612 - val_loss: 1.1326 - val_accuracy: 0.7381\n",
      "Epoch 424/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.8469 - val_loss: 0.9751 - val_accuracy: 0.7762\n",
      "Epoch 425/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.8531 - val_loss: 1.0256 - val_accuracy: 0.7619\n",
      "Epoch 426/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.8660 - val_loss: 1.0069 - val_accuracy: 0.7508\n",
      "Epoch 427/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.8680 - val_loss: 1.0158 - val_accuracy: 0.7635\n",
      "Epoch 428/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9529 - accuracy: 0.7986 - val_loss: 1.1134 - val_accuracy: 0.7429\n",
      "Epoch 429/550\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7996 - accuracy: 0.8286 - val_loss: 1.1080 - val_accuracy: 0.7333\n",
      "Epoch 430/550\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.8823 - val_loss: 0.9379 - val_accuracy: 0.7841\n",
      "Epoch 431/550\n",
      "79/98 [=======================>......] - ETA: 0s - loss: 0.7040 - accuracy: 0.8700"
     ]
    }
   ],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(lr=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=550, batch_size=15,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# score = model.predict_classes(X_test)\n",
    "# y_true = [np.where(x == 1)[0][0] for x in y_test]\n",
    "\n",
    "predict_x=model.predict(X_test) \n",
    "score=np.argmax(predict_x,axis=1)\n",
    "y_true = y_test\n",
    "\n",
    "print('Acurácia: %0.2f%%' % (accuracy_score(y_true, score) * 100))\n",
    "print('Matriz de confusão:')\n",
    "print(confusion_matrix(y_true, score))\n",
    "print()\n",
    "print(classification_report(y_true, score, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfaa7d",
   "metadata": {},
   "source": [
    "# Grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0de8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b428c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
